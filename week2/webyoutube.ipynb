{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2b9de4-a12b-4590-96eb-aafc92db19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv add openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4969520-a53b-4c12-940b-c3c0558c4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecdf08a7-0dca-4351-8b81-501cca93fdab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38146173-197f-4756-a2ea-3f638cde514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv remove openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fbf42e-7bee-43f1-a719-96b33e447ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv add openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40818013-5172-41b0-b044-9c4242597ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, function_tool, Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf8138f-87f4-4dd9-8794-f696de05d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3cf2b1-6678-40e3-befc-ca5e9b860606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.stromnetz.berlin'\n",
    "def fetch_url(url):\n",
    "    jina_reader_url = base_url + url\n",
    "    response = requests.get(jina_reader_url)\n",
    "    return response.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c34011c-f625-4c07-b186-f7b24d389662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167b2100-246d-4fc8-874d-9ef8113cbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import RequestException, Timeout, HTTPError\n",
    "\n",
    "def fetch_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the content of a given URL by appending it to the base URL and performing an HTTP GET request.\n",
    "\n",
    "    Args:\n",
    "        url (str): The relative or absolute URL path to fetch.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        str: The decoded text content of the response.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the URL or response content is invalid or cannot be decoded.\n",
    "        HTTPError: If the HTTP request returns an unsuccessful status code.\n",
    "        Timeout: If the request times out.\n",
    "        RequestException: For general network-related errors.\n",
    "    \"\"\"\n",
    "    base_url = 'https://r.jina.ai/'\n",
    "    jina_reader_url = base_url + url\n",
    "    try:\n",
    "        response = requests.get(jina_reader_url, timeout=10)\n",
    "        response.raise_for_status()  # Raises HTTPError for bad status codes\n",
    "        try:\n",
    "            return response.content.decode(\"utf-8\")\n",
    "        except UnicodeDecodeError as e:\n",
    "            raise ValueError(f\"Failed to decode response content from {jina_reader_url}\") from e\n",
    "    except Timeout as e:\n",
    "        raise Timeout(f\"Request to {jina_reader_url} timed out.\") from e\n",
    "    except HTTPError as e:\n",
    "        raise HTTPError(f\"HTTP error occurred while fetching {jina_reader_url}: {e}\") from e\n",
    "    except RequestException as e:\n",
    "        raise RequestException(f\"Error occurred while requesting {jina_reader_url}: {e}\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3986cef-f3a7-4fb1-b92c-360b4b25a4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Stromnetz Berlin | Berlins zuverlässiger Netzbetreiber\\n\\nURL Source: https://www.stromnetz.berlin/\\n\\nMarkdown Content:\\nStromnetz Berlin | Berlins zuverlässiger Netzbetreiber\\n\\n===============\\n[Zum Hauptinhalt springen](https://www.stromnetz.berlin/#_main)[Zur Navigation springen](https://www.stromnetz.berlin/#_mainnav)[Zur Suche springen](https://www.stromnetz.berlin/#)\\n\\nGeöffnen Shclisen\\n\\n[![Image 1: Logotype](https://www.stromnetz.berlin/files/ui/images/logo/logotype.svg)](https://www.stromnetz.berlin/)\\n\\n*   Anschließen \\n    *   [Anschließen](https://www.stromnetz.berlin/anschliessen/)\\n    *   [Anschluss Niederspannung](https://www.stromnetz.berlin/anschliessen/anschluss-niederspannung/)\\n        *   [Inspektion Netzanschluss](https://www.stromnetz.berlin/anschliessen/anschluss-niederspannung/inspektion-netzanschluss/)\\n\\n    *   [Anschluss Mittel- und Hochspannung](https://www.stromnetz.berlin/anschliessen/anschluss-mittel-hochspannung/)\\n        *   [Anlagensicherheit](https://www.stromnetz.berlin/anschliessen/anschluss-mittel-hochspannung/anlagensicherheit/)\\n        *   [Repartierungsverfahren](https://www.stromnetz.berlin/anschliessen/anschluss-mittel-hochspannung/repartierung/)\\n\\n    *   [Erzeugungsanlagen und Speicher](https://www.stromnetz.berlin/anschliessen/erzeugungsanlagen-und-speicher/)\\n    *   [Elektromobilität](https://www.stromnetz.berlin/anschliessen/elektromobilitat/)\\n        *   [Ladeinfrastruktur für Elektromobilität](https://www.stromnetz.berlin/anschliessen/elektromobilitat/ladeinfrastruktur-elektromobilitaet/)\\n        *   [E-Mobilität und Stromnetz](https://www.stromnetz.berlin/anschliessen/elektromobilitat/e-mobilitaet-und-stromnetz/)\\n        *   [Fragen und Antworten Elektromobilität](https://www.stromnetz.berlin/anschliessen/elektromobilitat/fragen-und-antworten-elektromobilitat/)\\n        *   [Alles geregelt: Dokumente & Rechtliches](https://www.stromnetz.berlin/anschliessen/elektromobilitat/alles-geregelt-dokumente-und-rechtliches/)\\n\\n    *   [Leitungsauskunft](https://www.stromnetz.berlin/anschliessen/leitungsauskunft/)\\n\\n*   Einspeisen \\n    *   [Einspeisen](https://www.stromnetz.berlin/einspeisen/)\\n    *   [Erneuerbare Energien](https://www.stromnetz.berlin/einspeisen/erneuerbare-energien/)\\n    *   [Sonne vom Balkon](https://www.stromnetz.berlin/einspeisen/sonne-vom-balkon/)\\n    *   [Erzeugungsanlagen](https://www.stromnetz.berlin/einspeisen/erzeugungsanlagen-einspeisung/)\\n    *   [Kraft-Wärme-Kopplung](https://www.stromnetz.berlin/einspeisen/kraft-warme-kopplung/)\\n    *   [Einspeisemanagement](https://www.stromnetz.berlin/einspeisen/einspeisemanagement/)\\n    *   [Redispatch](https://www.stromnetz.berlin/einspeisen/redispatch/)\\n\\n*   Zähler \\n    *   [Zähler](https://www.stromnetz.berlin/zahler/)\\n    *   [Kundeninformationen und Hilfe](https://www.stromnetz.berlin/zahler/kundeninformationen/)\\n        *   [Prüfung von Zählern](https://www.stromnetz.berlin/zahler/kundeninformationen/prufung-von-zahlern/)\\n        *   [Beschwerden und Schlichtung](https://www.stromnetz.berlin/zahler/kundeninformationen/beschwerden-und-schlichtung/)\\n        *   [Zählerreklamation](https://www.stromnetz.berlin/zahler/kundeninformationen/zahlerreklamation/)\\n        *   [Sperrung / Unterbrechung](https://www.stromnetz.berlin/zahler/kundeninformationen/sperrung--unterbrechung/)\\n        *   [Eichung](https://www.stromnetz.berlin/zahler/kundeninformationen/eichung-von-zaehlern/)\\n        *   [Schadenersatz](https://www.stromnetz.berlin/zahler/kundeninformationen/schadenersatz/)\\n        *   [Kontaktaufnahme](https://www.stromnetz.berlin/zahler/kundeninformationen/kontaktaufnahme/)\\n\\n    *   [Zählerablesung](https://www.stromnetz.berlin/zahler/zahlerablesung/)\\n    *   [Montage, Demontage und Tausch von Zählern](https://www.stromnetz.berlin/zahler/montage-demontage-und-tausch-von-zahlern/)\\n    *   [Digitale Zähler](https://www.stromnetz.berlin/zahler/digitale-zahler/)\\n        *   [Moderne Messeinrichtung](https://www.stromnetz.berlin/zahler/digitale-zahler/moderne-messeinrichtung/)\\n        *   [Intelligentes Messsystem](https://www.stromnetz.berlin/zahler/digitale-zahler/intelligentes-messsystem/)\\n        *   [Informationen grundzuständiger Messstellenbetreiber](https://www.stromnetz.berlin/zahler/digitale-zahler/informationen-grundzustandiger-messstellenbetreiber/)\\n\\n    *   [Anleitungen für Zähler](https://www.stromnetz.berlin/zahler/anleitungen-fur-zahler/)\\n    *   [Einzug, Auszug, Umzug und Lieferantenwechsel](https://www.stromnetz.berlin/zahler/einzug-auszug-und-lieferantenwechsel/)\\n\\n*   Netz nutzen \\n    *   [Netz nutzen](https://www.stromnetz.berlin/netz-nutzen/)\\n    *   [Netznutzer](https://www.stromnetz.berlin/netz-nutzen/netznutzer/)\\n    *   [Entgelte](https://www.stromnetz.berlin/netz-nutzen/entgelte/)\\n    *   [Steuerbare Verbrauchseinrichtungen](https://www.stromnetz.berlin/netz-nutzen/steuerbare-verbrauchseinrichtungen/)\\n    *   [Grundzuständiger Messstellenbetreiber](https://www.stromnetz.berlin/netz-nutzen/grundzustandiger-messstellenbetreiber/)\\n    *   [Messstellenbetrieb](https://www.stromnetz.berlin/netz-nutzen/messstellenbetrieb/)\\n    *   [Ausschreibung Netzverlustenergie](https://www.stromnetz.berlin/netz-nutzen/ausschreibung-netzverlustenergie/)\\n        *   [Ausschreibung Kurzfristkomponente 2026](https://www.stromnetz.berlin/netz-nutzen/ausschreibung-netzverlustenergie/ausschreibung-kurzfristkomponente-2026/)\\n        *   [5. Ausschreibung Netzverlustenergie für 2027](https://www.stromnetz.berlin/netz-nutzen/ausschreibung-netzverlustenergie/ausschreibung-verlustenergie-2027-nr-5/)\\n        *   [Veröffentlichung Ergebnisse](https://www.stromnetz.berlin/netz-nutzen/ausschreibung-netzverlustenergie/veroeffentlichung-ergebnisse/)\\n        *   [Archiv Ausschreibungsunterlagen](https://www.stromnetz.berlin/netz-nutzen/ausschreibung-netzverlustenergie/archiv-ausschreibungsunterlagen/)\\n\\n    *   [Ausschreibung Blindleistung](https://www.stromnetz.berlin/netz-nutzen/ausschreibung-blindleistung/)\\n    *   [Meldung Selbst-/Drittverbrauch](https://www.stromnetz.berlin/netz-nutzen/meldung-selbstverbrauch-drittverbrauch/)\\n\\n*   Beleuchtung\\n    *   [Beleuchtung](https://www.stromnetz.berlin/beleuchtung/)\\n    *   [Betrieb Beleuchtungsanlagen](https://www.stromnetz.berlin/beleuchtung/betrieb-beleuchtungsanlagen/)\\n    *   [Projektierung und Bau Beleuchtungsanlagen](https://www.stromnetz.berlin/beleuchtung/projektierung-und-bau-beleuchtungsanlagen/)\\n    *   [Referenzen Beleuchtungsprojekte](https://www.stromnetz.berlin/beleuchtung/referenzen-beleuchtungsprojekte/)\\n\\n*   Karriere \\n    *   [Karriere](https://www.stromnetz.berlin/karriere/)\\n    *   [Jobs](https://www.stromnetz.berlin/karriere/jobs/)\\n    *   [Ausbildung und duales Studium](https://www.stromnetz.berlin/karriere/ausbildung-und-duales-studium/)\\n    *   [Student*innen](https://www.stromnetz.berlin/karriere/student_innen/)\\n    *   [Arbeiten bei uns](https://www.stromnetz.berlin/karriere/arbeiten-bei-uns/)\\n\\n*   Über uns \\n    *   [Über uns](https://www.stromnetz.berlin/uber-uns/)\\n    *   [Management](https://www.stromnetz.berlin/uber-uns/management/)\\n    *   [Presse und News](https://www.stromnetz.berlin/uber-uns/presse/)\\n    *   [Zahlen, Daten, Fakten](https://www.stromnetz.berlin/uber-uns/zahlen-daten-fakten/)\\n    *   [Veröffentlichungspflichten](https://www.stromnetz.berlin/uber-uns/veroffentlichungspflichten/)\\n        *   [Energiewirtschaftsgesetz (EnWG)](https://www.stromnetz.berlin/uber-uns/veroffentlichungspflichten/energiewirtschaftsgesetz-enwg/)\\n        *   [Stromnetzentgeltverordnung (StromNEV)](https://www.stromnetz.berlin/uber-uns/veroffentlichungspflichten/stromnetzentgeltverordnung-stromnev/)\\n        *   [Kraftwerksnetzanschlussverordnung (KraftNAV)](https://www.stromnetz.berlin/uber-uns/veroffentlichungspflichten/kraftwerksnetzanschlussverordnung-kraftnav/)\\n        *   [Anreizregulierungsverordnung (ARegV)](https://www.stromnetz.berlin/uber-uns/veroffentlichungspflichten/anreizregulierungsverordnung-aregv/)\\n        *   [Lieferkettensorgfaltspflichtengesetz (LkSG)](https://www.stromnetz.berlin/uber-uns/veroffentlichungspflichten/lieferkettensorgfaltspflichtengesetz/)\\n        *   [Verordnung über Integrität und Transparenz des Energiegroßhandelsmarkts (REMIT)](https://www.stromnetz.berlin/uber-uns/veroffentlichungspflichten/remit/)\\n        *   [Barrierefreiheitserklärung der Stromnetz Berlin GmbH](https://www.stromnetz.berlin/uber-uns/veroffentlichungspflichten/barrierefreiheitserklarung-der-stromnetz-berlin-gmbh/)\\n\\n    *   [Geschäftsberichte](https://www.stromnetz.berlin/uber-uns/geschaftsberichte/)\\n    *   [Nachhaltigkeit](https://www.stromnetz.berlin/uber-uns/nachhaltigkeit/)\\n        *   [Strategie und Management](https://www.stromnetz.berlin/uber-uns/nachhaltigkeit/strategie-und-nachhaltigkeitsmanagement/)\\n        *   [Energiewende und Kundenorientierung](https://www.stromnetz.berlin/uber-uns/nachhaltigkeit/energiewende-und-kundenorientierung/)\\n        *   [Umwelt- und Klimaschutz](https://www.stromnetz.berlin/uber-uns/nachhaltigkeit/umwelt-und-klimaschutz/)\\n        *   [Zusammenarbeit](https://www.stromnetz.berlin/uber-uns/nachhaltigkeit/zusammenarbeit/)\\n        *   [Verantwortung](https://www.stromnetz.berlin/uber-uns/nachhaltigkeit/verantwortung/)\\n\\n    *   [Zertifizierungen](https://www.stromnetz.berlin/uber-uns/zertifizierungen/)\\n    *   [Compliance](https://www.stromnetz.berlin/uber-uns/compliance/)\\n    *   [Unsere Geschichte](https://www.stromnetz.berlin/uber-uns/unsere-geschichte/)\\n\\n*   Für Berlin \\n    *   [Für Berlin](https://www.stromnetz.berlin/fur-berlin/)\\n    *   [Stromkastenstyling](https://www.stromnetz.berlin/fur-berlin/stromkastenstyling/)\\n        *   [Stromkastenstyling 2025](https://www.stromnetz.berlin/fur-berlin/stromkastenstyling/stromkastenstyling-2025/)\\n        *   [Stromkastenstyling 2024](https://www.stromnetz.berlin/fur-berlin/stromkastenstyling/stromkastenstyling-2024/)\\n        *   [Stromkastenstyling 2023](https://www.stromnetz.berlin/fur-berlin/stromkastenstyling/stromkastenstyling-2023/)\\n        *   [Stromkastenstyling 2022](https://www.stromnetz.berlin/fur-berlin/stromkastenstyling/stromkastenstyling-2022/)\\n        *   [Stromkastenstyling 2021](https://www.stromnetz.berlin/fur-berlin/stromkastenstyling/stromkastenstyling-2021/)\\n\\n    *   [Bürger*innenrat](https://www.stromnetz.berlin/fur-berlin/buerger-innenrat/)\\n        *   [Bewerbung zum Bürger*innenrat](https://www.stromnetz.berlin/fur-berlin/buerger-innenrat/bewerbung-zum-buerger_innenrat/)\\n\\n    *   [Bürger*innendialog](https://www.stromnetz.berlin/fur-berlin/buerger_innendialog/)\\n    *   [Vielfalt für Berlin](https://www.stromnetz.berlin/fur-berlin/vielfalt-fur-berlin/)\\n        *   [Queer durch Berlin](https://www.stromnetz.berlin/fur-berlin/vielfalt-fur-berlin/queer-durch-berlin/)\\n        *   [Bündnis gegen Homophobie](https://www.stromnetz.berlin/fur-berlin/vielfalt-fur-berlin/bundnis-gegen-homophobie/)\\n\\n    *   [Smart City](https://www.stromnetz.berlin/fur-berlin/smart-city/)\\n    *   [Umweltschutz](https://www.stromnetz.berlin/fur-berlin/umweltschutz/)\\n        *   [Bienen im Einsatz](https://www.stromnetz.berlin/fur-berlin/umweltschutz/bienen-im-einsatz/)\\n\\n*   Partner\\n    *   [Partner](https://www.stromnetz.berlin/partner/)\\n    *   [Lieferanten und Vertragspartner](https://www.stromnetz.berlin/partner/lieferanten-und-vertragspartner/)\\n        *   [Lieferantenqualifizierung](https://www.stromnetz.berlin/partner/lieferanten-und-vertragspartner/lieferantenqualifizierung/)\\n        *   [Lieferantenanmeldung](https://www.stromnetz.berlin/partner/lieferanten-und-vertragspartner/lieferantenanmeldung/)\\n        *   [Nachhaltigkeit und Compliance](https://www.stromnetz.berlin/partner/lieferanten-und-vertragspartner/nachhaltigkeit-und-compliance/)\\n\\n    *   [Installateure](https://www.stromnetz.berlin/partner/installateure/)\\n        *   [Zählerbeantragung / -montage](https://www.stromnetz.berlin/partner/installateure/zahlerbeantragung-montage/)\\n        *   [Installateurverzeichnis](https://www.stromnetz.berlin/partner/installateure/installateurverzeichnis/)\\n        *   [Installateur-Unterlagen](https://www.stromnetz.berlin/partner/installateure/installateur-unterlagen/)\\n        *   [Zähler-Packstation](https://www.stromnetz.berlin/partner/installateure/zaehler-packstation/)\\n\\n    *   [Kooperationen](https://www.stromnetz.berlin/partner/kooperationen/)\\n\\n*   Technik & Innovation \\n    *   [Technik & Innovation](https://www.stromnetz.berlin/technik-und-innovationen/)\\n    *   [Störungsmanagement](https://www.stromnetz.berlin/technik-und-innovationen/storungsmanagement/)\\n    *   [Störungsmanagement öffentliche Beleuchtung](https://www.stromnetz.berlin/technik-und-innovationen/stoerungsmanagement-beleuchtung/)\\n    *   [Aufbau und Funktionsweise Stromnetz](https://www.stromnetz.berlin/technik-und-innovationen/aufbau-und-funktionsweise-stromnetz/)\\n    *   [Investitionen](https://www.stromnetz.berlin/technik-und-innovationen/investitionen/)\\n        *   [Baumaßnahmen](https://www.stromnetz.berlin/technik-und-innovationen/investitionen/baumassnahmen/)\\n\\n    *   [Unsere Online-Portale](https://www.stromnetz.berlin/technik-und-innovationen/unsere-online-portale/)\\n    *   [Open Data](https://www.stromnetz.berlin/technik-und-innovationen/open-data/)\\n\\n[de](https://www.stromnetz.berlin/)[en](https://www.stromnetz.berlin/en/)\\n\\nSuche\\n\\n### Unser Service\\n\\n**Unsere Online-Dienste**\\n\\n*   [Zählerstand erfassen](https://mein.stromnetz.berlin/web/zaehlerstand)\\n*   [Online Kundenanfrage](https://services.stromnetz.berlin/kontaktanfrage)\\n*   [24h-Störungsmanagement](https://www.stromnetz.berlin/technik-und-innovationen/storungsmanagement/)\\n*   [Kundenportal (Anschluss/Einspeiser)](https://kundenportal.stromnetz.berlin/#/welcome)\\n*   [Kundeninformationen](https://www.stromnetz.berlin/zahler/kundeninformationen)\\n\\n**Kundenanfragen**030 49202 0294\\n\\nMontag - Freitag, 8 - 18 Uhr\\n\\n![Image 2: Modernes Gebäude mit weitem Dach und Stützen und davor eine Skulptur unter leicht bewölktem Himmel.](https://www.stromnetz.berlin/images/3087e634-d1fa-439c-8046-af3776f564d5/dt/Skyline-Berlin_AdobeStock_161544948_3840x2160.jpg)\\n\\nStrom für\\n\\n**Sie**und**Berlin**zu jeder Zeit\\n============================================\\n\\n[![Image 3](https://www.stromnetz.berlin/images/4ce61fa4-ceed-49f7-84ea-cfd185780ae2/sp-l/3840x2160-Zaehlertafel.jpg) ### Zählerstand mitteilen Melden Sie Ihren Zählerstand für die jährliche Ablesung oder bei einem Ein-/Auszug oder Lieferantenwechsel über unser Kundenserviceportal.](https://mein.stromnetz.berlin/web/zaehlerstand)[![Image 4](https://www.stromnetz.berlin/images/375d5150-22b6-434c-8a28-d65db390a201/sp-l/Blackout_AdobeStock_676897591_2160x2160.jpg) ### Störungsmanagement 24h-Störungsmanagement für Berlin – wenn der Strom mal ausfällt haben wir Informationen zu der Störung und geben Hilfestellung](https://www.stromnetz.berlin/technik-und-innovationen/storungsmanagement/)[![Image 5](https://www.stromnetz.berlin/images/561d065e-8870-4547-bdb0-8bf2371e17cd/sp-l/800x420-Zaehlerablesung.jpg) ### Zählerablesung Informationen zur Zählerablesung - durch einen Dienstleister von Stromnetz Berlin oder durch Sie selbst.](https://www.stromnetz.berlin/zahler/zahlerablesung/)\\n\\n[![Image 6](https://www.stromnetz.berlin/images/a9cd740c-5c94-4931-84c9-29eb5f4911fe/sp-l/3840x2160-Kundengespraech.jpg) ### Kundeninformationen und Hilfe Informationen zu aktuellen und wichtigen Themen für Kund*innen, einer möglichen Kontaktaufnahme oder Beschwerden](https://www.stromnetz.berlin/zahler/kundeninformationen/)[![Image 7](https://www.stromnetz.berlin/images/53b27c5d-f0c2-4019-8799-376a074de953/sp-l/Buerger-innenrat-Kampagne_Motiv-2025.jpg) ### Bewerbung zum Bürger*innenrat Bewerben Sie sich für unseren Bürger*innenrat für die Legislaturperiode 2026-2029.](https://www.stromnetz.berlin/fur-berlin/buerger-innenrat/bewerbung-zum-buerger_innenrat/)[![Image 8](https://www.stromnetz.berlin/images/763e5d18-7f26-41ef-b3b0-3e9ee92f294a/sp-l/GB-Za-hlermontage-024.jpg) ### Montage, Demontage und Tausch von Zählern Informationen zum Einbau, Tausch und Ausbau von Zählern, modernen Messeinrichtungen und intelligenten Messsystemen](https://www.stromnetz.berlin/zahler/montage-demontage-und-tausch-von-zahlern/)\\n\\nPressemitteilungen\\n------------------\\n\\n[News 14.10.2025 Berliner Haushalte werden durch Bundeszuschüsse an die Übertragungsnetze entlastet](https://www.stromnetz.berlin/uber-uns/presse/pressemitteilungen-2025/berliner-haushalte-werden-durch-bundeszuschusse-an-die-ubertragungsnetze-entlastet/)[News 13.10.2025 Grün leuchtende Straßenlaternen nach kurzer Beleuchtungs\\xad-Störung](https://www.stromnetz.berlin/uber-uns/presse/pressemitteilungen-2025/grun-leuchtende-strasenlaternen-nach-kurzer-beleuchtungs-storung/)[News 23.09.2025 Investition in das Berliner Stromnetz: BEN und Europäische Investitionsbank unterzeichnen Kreditvertrag](https://www.stromnetz.berlin/uber-uns/presse/pressemitteilungen-2025/investition-in-das-berliner-stromnetz-ben-und-europaische-investitionsbank-unterzeichnen-kreditvertrag/)\\n\\n[Alle Pressemitteilungen](https://www.stromnetz.berlin/uber-uns/presse/)\\n\\nNeuigkeiten\\n-----------\\n\\n*   [Information 23.10.2025 5. Ausschreibung zur Beschaffung der Energie zur Deckung physikalischer Netzverluste für das Jahr 2027 veröffentlicht.](https://www.stromnetz.berlin/netz-nutzen/ausschreibung-netzverlustenergie/ausschreibung-verlustenergie-2027-nr-5/)\\n*   [Information 16.10.2025 Die Ausschreibung für die Dienstleistung zur Beschaffung der Kurzfristkomponente für Verlustenergiemengen für das Jahr 2026 ist veröffentlicht.](https://www.stromnetz.berlin/netz-nutzen/ausschreibung-netzverlustenergie/ausschreibung-kurzfristkomponente-2026/)\\n*   [Information 16.10.2025 Ergebnis der 4. Ausschreibung Netzverlustenergie für das Jahr 2027 veröffentlicht.](https://www.stromnetz.berlin/netz-nutzen/ausschreibung-netzverlustenergie/veroeffentlichung-ergebnisse/)\\n\\nUnsere Vision\\n-------------\\n\\nAus Liebe zu Berlin:\\n\\ndas modernste Stromnetz für die klimaneutrale Hauptstadt\\n\\nKontakt\\n-------\\n\\n**Adresse:**\\n\\nStromnetz Berlin GmbH\\n\\n10871 Berlin\\n\\n**Telefon:**\\n\\n030-492 02-0294\\n\\nMo-Fr, 8 - 18 Uhr\\n\\n**E-Mail:**\\n\\n[info@stromnetz-berlin.de](mailto:info@stromnetz-berlin.de)\\n\\nWichtige Links\\n--------------\\n\\n[Presse](https://www.stromnetz.berlin/uber-uns/presse/ \"Link zum Pressebereich\")\\n\\n[Installateur\\xad*innen](https://www.stromnetz.berlin/partner/installateure/ \"Informationen und Dokumente für Installateur*innen\")\\n\\n[Glossar](https://www.stromnetz.berlin/glossar/ \"Erfahre mehr zu den Begriffen der Energiewirtschaft in Glossar\")\\n\\n[Responsible disclosure](https://www.stromnetz.berlin/responsible-disclosure/ \"Informationen zur Meldung von Sicherheitslücken\")\\n\\nStörungsmanagement\\n------------------\\n\\n**Störungsnummer Strom**\\n\\n0800 211 2525 \\n\\n(kostenfrei)\\n\\n**Störungsnummer Öffentliche Beleuchtung**\\n\\n0800 110 2010\\n\\n(kostenfrei)\\n\\nFolge uns\\n---------\\n\\n[![Image 9: LinkedIn logotype](https://www.stromnetz.berlin/files/ui/images/icons/In-White-128.webp)](https://www.linkedin.com/company/stromnetzberlin/)[![Image 10: Youtube logotype](https://www.stromnetz.berlin/files/ui/images/icons/youtube_monochrome_light_icon.webp)](https://www.youtube.de/Stromnetzberlin)[![Image 11: X logotype](https://www.stromnetz.berlin/files/ui/images/icons/X-logo-white.webp)](https://x.com/stromnetzbln)\\n\\n*   [Impressum](https://www.stromnetz.berlin/impressum/ \"Angaben zu unseren Verantwortlichen\")\\n*   [Datenschutz](https://www.stromnetz.berlin/datenschutz/ \"Link zur Datenschutzerklärung\")\\n*   [Barrierefreiheitserklärung](https://www.stromnetz.berlin/uber-uns/veroffentlichungspflichten/barrierefreiheitserklarung-der-stromnetz-berlin-gmbh/ \"Link zur Barrierefreiheitserklärung\") \\n*   [Über Cookies](https://www.stromnetz.berlin/ueber-cookies/ \"Informationen zu dem Einsatz von Cookies\")\\n*   [Sitemap](https://www.stromnetz.berlin/sitemap/ \"Link zu einer alternativen Darstellungen der Seitenstruktur\")\\n\\nCookie-Einstellungen\\n--------------------\\n\\n[DE](https://www.stromnetz.berlin/)[EN](https://www.stromnetz.berlin/en)\\n\\nIn der Regel können Sie die Seiten der Stromnetz Berlin GmbH besuchen, ohne dass wir personenbezogene Daten von Ihnen benötigen.\\n\\nWir verwenden technisch notwendige Cookies für den sicheren Betrieb der Webseite. Um das Angebot auf unserer Webseite für Sie möglichst komfortabel zu gestalten verwenden wir ebenfalls Cookies. Des Weiteren nutzen wir Cookies für anonyme Statistiken zur Nutzung unserer Webseite.\\n\\nSoweit keine technische Notwendigkeit besteht, entscheiden Sie selbst darüber, welche Cookies Sie zulassen möchten und welche nicht. Die Auswahl kann jederzeit geändert werden.\\n\\nWeitere Informationen zur Stromnetz Berlin GmbH finden Sie unter [Impressum](https://www.stromnetz.berlin/impressum/) und [Datenschutz](https://www.stromnetz.berlin/datenschutz/).\\n\\n- [x]  Notwendig\\n\\n- [x]  Statistik\\n\\n- [x]  Komfort\\n\\n[Details](https://www.stromnetz.berlin/)\\n\\n**Notwendig**\\n\\nTechnisch notwendige Cookies sind für das ordnungsgemäße und sichere Funktionieren der Webseite unbedingt erforderlich. Ohne diese Cookies kann unsere Webseite nicht wie vorgesehen genutzt werden. Diese Cookies sind immer aktiviert und können nicht deaktiviert werden. Eine Deaktivierung in Ihrem Browser kann dazu führen, dass die Webseite nicht ordnungsgemäß funktioniert.\\n\\n**Statistik**Statistische Cookies werden eingesetzt, um statistische Analysen zur Nutzung unserer Webseite und zur Wahrnehmung des Webauftritts durchzuführen. Hierfür werden Statistiken generiert, die einen Überblick über Besuche und Zugriffsquellen geben. Auf Basis der gesammelten statistischen Daten werden Schwachstellen analysiert und Optimierungsmaßnahmen ausgearbeitet, um Funktionalität, Inhalt und Attraktivität der Webseite zu verbessern. Diese Art von Cookies kann auch in Zusammenarbeit mit unseren Entwicklern verwendet werden. Diese Cookies sammeln keine Informationen, die mit Ihnen als Einzelperson in Verbindung gebracht werden können und sind vollständig anonym.\\n\\n**Komfort**\\n\\nCookies zum Komfort werden von Stromnetz Berlin eingesetzt, um Ihnen den Besuch so komfortable wie möglich zu gestalten. Hierbei werden Ihr Browser und Endgerät eindeutig identifiziert.\\n\\n[Siehe detaillierte Cookie-Liste](https://www.stromnetz.berlin/)\\n\\n| Name | Kategorie | Anbieter | Zweck | Ablauf | HTTP |\\n| --- | --- | --- | --- | --- | --- |\\n|  |\\n| cookieAgree | Notwendig | Comprend WaaS | In diesem Cookie werden die vom Benutzer bestätigten Cookie-Kategorien des Cookie Einwilligungsmanagements dokumentiert. | 90 Tage | Nein |\\n| cookieSelection | Notwendig | Comprend WaaS | In diesem Cookie werden die vom Benutzer bestätigten Cookie-Kategorien des Cookie Einwilligungsmanagements dokumentiert. | 90 Tage | Nein |\\n| crisisnotice | Notwendig | Comprend WaaS | In diesem Cookie wird die Benutzerbestätigung zum Schließen des Krisen-Popups dokumentiert. | Session | Nein |\\n| _pk_id | Statistik | Matomo Analytics | Dieser Cookie speichert eine Benutzer ID und wird genutzt, um eine Statistik für die Stromnetz Berlin GmbH zu füllen. Die Statistik dient als Grundlage, um das Besucherverhalten zu analysieren und Verbesserungen zu erzielen. Die Statistik selber ist anonymisiert. | 13 Monate | Nein |\\n| _pk_ref | Statistik | Matomo Analytics | Dieser Cookie wird verwendet, um die Attribute zu speichern, die ursprünglich zum Besuch der Website verwendet wurden. | 6 Monate | Nein |\\n| _pk_ses | Statistik | Matomo Analytics | Dieser Cookie speichert für kurze Zeit das Besucherverhalten und wird genutzt, um eine Statistik für die Stromnetz Berlin GmbH zu füllen. Die Statistik dient als Grundlage, um das Besucherverhalten zu analysieren und Verbesserungen zu erzielen. Die Statistik selber ist anonymisiert. | 30 Minuten | Nein |\\n| _pk_testcookie | Statistik | Matomo Analytics | Dieser Cookie wird eingesetzt zur Prüfung, ob der Browser Cookies unterstützt. | Wird erstellt und sofort wieder gelöscht | Nein |\\n| Multiple | Komfort | Google/Youtube | Für die Anzeige von Videos auf unserer Webseite nutzen wir Youtube und der Videoplayer bzw. die Webseite von YouTube setzt Cookies auf Ihrem Computer. Ausführliche Informationen zu diesen Cookies und deren Einsatz finden Sie auf der [Website](https://policies.google.com/technologies/cookies?hl=en-US#how-google-uses-cookies) von Youtube (Google). | Various |  |\\n\\nAuswahl speichern\\n\\nAlle auswählen und akzeptieren\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6be3d80-1c6c-4daf-8904-0bbe646cf4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_agent= Agent(\n",
    "    name='web_agent',\n",
    "    instructions='you are a helpful assistant',\n",
    "    model='gpt-4o-mini',\n",
    "    tools = [function_tool(fetch_url)]\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c33eb241-4f7d-404b-b425-7f9ce9c9d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is this page about? https://www.stromnetz.berlin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10ae503c-66d0-4547-9745-cd61fe63f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77e9f392-3d8d-4f3e-8d3c-a4ee4bceaba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await runner.run(web_agent,input=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21c35be7-409e-4238-ac35-5112ab8734e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The website **Stromnetz Berlin** serves as the official portal for Berlin's electricity grid operator. Here are the main points about it:\\n\\n1. **Core Services**:\\n   - Connection to the electricity network for various voltage levels (low, medium, high).\\n   - Infrastructure for renewable energy integration and electric mobility solutions.\\n   - Metering services including installation, reading, and management of electricity meters.\\n\\n2. **Public Information**:\\n   - Information on maintenance, troubleshooting, and outages.\\n   - Customer services such as online reporting systems and FAQs.\\n\\n3. **Corporate Overview**:\\n   - Details about the company, its management, sustainability efforts, and legal information.\\n   - Career opportunities in the company.\\n\\n4. **Community Engagement**:\\n   - Initiatives aimed at improving community relations, including citizen councils and environmental projects.\\n\\n5. **Innovation and Technology**:\\n   - Updates on technological advancements and infrastructure investments related to electricity supply.\\n\\nOverall, the site provides essential services and resources for electrical supply in Berlin, emphasizing reliability, sustainability, and community involvement.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b9039e-da73-45e2-aca5-c343043f9db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_page_content(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch the textual content of a webpage using the Jina AI Reader service.\n",
    "\n",
    "    This function prefixes the provided URL with Jina AI's reader endpoint \n",
    "    (`https://r.jina.ai/`), sends a GET request to that endpoint, and returns \n",
    "    the UTF-8 decoded content of the response.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the webpage to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The decoded UTF-8 content of the requested page.\n",
    "\n",
    "    Raises:\n",
    "        requests.RequestException: If an error occurs during the HTTP request.\n",
    "    \"\"\"\n",
    "    reader_url_prefix = 'https://r.jina.ai/'\n",
    "    request_url = reader_url_prefix + url\n",
    "    response = requests.get(request_url)\n",
    "    response.raise_for_status()  # optional but recommended for robustness\n",
    "    return response.content.decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda9f5bf-c503-43ec-a508-fb16b231eca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Title: Welcome to DataTalks.Club\\n\\nURL Source: https://datatalks.club/\\n\\nPublished Time: Tue, 21 Oct 2025 12:52:05 GMT\\n\\nMarkdown Content:\\nWelcome to DataTalks.Club\\n\\n===============\\n\\nAI Dev Tools Zoomcamp: Learn AI-powered coding assistants and agents[Register here!](https://airtable.com/appJRFiWKHBgmEt70/shrpw7rk55Ewr1jCG)\\n\\nDataTalks.Club\\n--------------\\n\\n[Articles](https://datatalks.club/articles.html)[Slack](https://datatalks.club/slack.html)[Events](https://datatalks.club/events.html)[Podcast](https://datatalks.club/podcast.html)[Books](https://datatalks.club/books.html)[Courses](https://datatalks.club/blog/guide-to-free-online-courses-at-datatalks-club.html)\\n\\n* * *\\n\\nThe place to talk about data\\n============================\\n\\nGlobal online community of data science professionals, ML engineers, and AI practitioners\\n-----------------------------------------------------------------------------------------\\n\\nSubscribe to our weekly newsletter and join our Slack.\\n\\n We'll keep you informed about everything happening in the Club.\\n\\nEmail \\n\\n Join \\n\\n You'll get an invite within 3 minutes \\n\\n![Image 4: Data science discussions and talks](https://datatalks.club/images/landing/talks.jpg)\\n\\n#### Talk about data, machine\\n\\n learning, and engineering\\n\\n![Image 5: Data science events and courses](https://datatalks.club/images/landing/events.jpg)\\n\\n#### Attend weekly events\\n\\n and learn from free courses\\n\\n![Image 6: Career guidance and mentorship](https://datatalks.club/images/landing/career.jpg)\\n\\n#### Ask career questions and\\n\\n discuss career options\\n\\n* * *\\n\\n#### Upcoming events\\n\\n*   [How to Build and Evaluate AI systems in the Age of LLMs](https://luma.com/w65omumd) on 21 Oct 2025 by [Hugo Bowne-Anderson](https://datatalks.club/people/hugobowneanderson.html)\\n*   [From Black-Box Systems to Augmented Decision-Making](https://luma.com/gqmsx9zd) on 28 Oct 2025 by [Anusha Akkina](https://datatalks.club/people/anushaakkina.html)\\n*   [Deep Learning with PyTorch](https://luma.com/vc02zy6a) on 28 Oct 2025 by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html)\\n*   [Practical guide: Fine-tuning Qwen3 with LoRA](https://luma.com/n41kqkfh) on 30 Oct 2025 by [Ivan Potapov](https://datatalks.club/people/ivanpotapov.html)\\n*   [AI Dev Tools Zoomcamp 2025 Pre-Course Live Q&A](https://luma.com/6p356li5) on 04 Nov 2025 by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html)\\n*   [Reinventing a Career in Tech](https://luma.com/ifmqg2xb) on 17 Nov 2025 by [Xia He-Bleinagel](https://datatalks.club/people/xiahebleinagel.html)\\n*   [AI Dev Tools Zoomcamp 2025 Course Launch](https://luma.com/80ve8r1u) on 18 Nov 2025 by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html)\\n*   [The Future of AI Agents](https://luma.com/0s0dcpdl) on 10 Feb 2026 by [Aditya Gautam](https://datatalks.club/people/adityagautam.html)\\n\\nCheck [events](https://datatalks.club/events.html) for all past events. You can also subscribe to [our Google calendar](https://calendar.google.com/calendar/?cid=ZjhxaWRqbnEwamhzY3A4ODA5azFlZ2hzNjBAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ) to get notified about all our events.\\n\\n#### Latest podcast episodes\\n\\n*   [Lessons from Applied AI: Tesla, Waymo, and Beyond](https://datatalks.club/podcast/s22e02-lessons-from-applied-ai-tesla-waymo-and-beyond.html) with [Aishwarya Jadhav](https://datatalks.club/people/aishwaryajadhav.html)\\n*   [Building reliable AI products in the era of Gen AI and Agents](https://datatalks.club/podcast/s22e01-building-reliable-ai-products-in-era-of-gen-ai-and-agents.html) with [Ranjitha Kulkarni](https://datatalks.club/people/ranjithakulkarni.html)\\n*   [From Theme Parks to Tesla: Building Data Products That Work](https://datatalks.club/podcast/s21e09-from-theme-parks-to-tesla-building-data-products-that-work.html) with [Abouzar Abbaspour](https://datatalks.club/people/abouzarabbaspour.html)\\n*   [From Semiconductors to Machine Learning: A Career in Data and Teaching](https://datatalks.club/podcast/s21e08-from-semiconductors-to-machine-learning-career-in-data-and-teaching.html) with [Dashel Ruiz Perez](https://datatalks.club/people/dashelruizperez.html)\\n*   [Lessons from Two Decades of AI](https://datatalks.club/podcast/s21e07-lessons-from-two-decades-of-ai.html) with [Micheal Lanham](https://datatalks.club/people/micheallanham.html)\\n\\nCheck the [podcast](https://datatalks.club/podcast.html) page for all past podcast episodes.\\n\\n#### Our Sponsors\\n\\n[![Image 7: dltHub](https://datatalks.club/images/partners/dlthub.png)](https://dlthub.com/)\\n\\n[![Image 8: Astronomer](https://datatalks.club/images/partners/astronomer.png)](https://www.astronomer.io/)\\n\\n[![Image 9: Arize AI](https://datatalks.club/images/partners/arize.png)](https://arize.com/model-monitoring/)\\n\\n#### Book of the week\\n\\nCheck the [book of the week](https://datatalks.club/books.html) page for more books!\\n\\n#### Latest articles\\n\\n*   [AI Dev Tools Zoomcamp 2025: Free Course to Master Coding Assistants, Agents, and Automation](https://datatalks.club/blog/ai-dev-tools-zoomcamp-2025-free-course-to-master-coding-assistants-agents-and-automation.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\\n*   [20+ Best Data Science Slack Communities to Join in 2025](https://datatalks.club/blog/slack-communities.html) by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html), [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\\n*   [A Guide to Free Online Courses at DataTalks.Club](https://datatalks.club/blog/guide-to-free-online-courses-at-datatalks-club.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\\n*   [Data Engineering Zoomcamp 2026: Free Data Engineering Course and Certification](https://datatalks.club/blog/data-engineering-zoomcamp.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\\n*   [ML Zoomcamp 2025: Free Machine Learning Engineering Course and Certification](https://datatalks.club/blog/machine-learning-zoomcamp.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\\n\\n* * *\\n\\n DataTalks.Club. Hosted on [GitHub Pages](https://github.com/DataTalksClub/datatalksclub.github.io). We use cookies.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_page_content('https://datatalks.club')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f84c4cb-a235-4b56-bf50-88ba2d7c06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, function_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91c14427-109b-4984-94c0-3432b23ea1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_instruction=\"\"\"\n",
    "You're a helpful assistant that helps answer user questions\n",
    "\"\"\"\n",
    "\n",
    "assistant = Agent(\n",
    "    name='assistant',\n",
    "    tools=[function_tool(fetch_url)],\n",
    "    instructions = assistant_instruction,\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4fff113-b11d-44ff-b1d5-94c92b4557d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "runner = Runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a39af737-3431-42ff-a69a-1a94ff6e9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Summarize the content of https://openai.github.io/openai-agents-python/\"\n",
    "result = await runner.run(assistant, input=user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6baa974f-7cd1-4481-b534-6ae2f35bb10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The **OpenAI Agents SDK** provides a framework for building agentic AI applications in Python with minimal abstractions. Here are the key points:\n",
      "\n",
      "### Overview\n",
      "- The SDK allows developers to create apps using Large Language Models (LLMs) that can interact with instructions and tools.\n",
      "- Key components include:\n",
      "  - **Agents** for executing tasks\n",
      "  - **Handoffs** to delegate tasks between agents\n",
      "  - **Guardrails** for input/output validation\n",
      "  - **Sessions** to maintain conversation history\n",
      "\n",
      "### Benefits\n",
      "1. **Simplicity**: Offers essential features without over-complication, allowing quick learning.\n",
      "2. **Flexibility**: Easy to customize and works well out-of-the-box.\n",
      "\n",
      "### Features\n",
      "- Built-in agent loop for handling tasks.\n",
      "- Integration with Python’s language capabilities.\n",
      "- Management of conversation history automatically.\n",
      "- Tracing for visualization and debugging.\n",
      "\n",
      "### Installation\n",
      "You can install the SDK using:\n",
      "```bash\n",
      "pip install openai-agents\n",
      "```\n",
      "\n",
      "### Example\n",
      "A simple example involves initializing an agent and executing a task:\n",
      "```python\n",
      "from agents import Agent, Runner\n",
      "\n",
      "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
      "result = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\n",
      "print(result.final_output)\n",
      "```\n",
      "\n",
      "### Additional Resources\n",
      "The SDK provides extensive documentation and examples for various applications and scenarios. For more information, visit the [OpenAI Agents documentation](https://openai.github.io/openai-agents-python/).\n"
     ]
    }
   ],
   "source": [
    "print(result.new_items[-1].raw_item.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2af14309-c263-431c-92a5-286c0d05ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import OpenAIAgentsSDKRunner\n",
    "\n",
    "chat_interface = IPythonChatInterface()\n",
    "runner = OpenAIAgentsSDKRunner(\n",
    "    chat_interface = chat_interface,\n",
    "    agent = assistant\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a29046a0-ad5d-42cc-94f0-cf40294442eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: what is https://openai.github.io/openai-agents-python/ about\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>fetch_url({\"url\":\"https://openai.github.io/openai-agents-...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"url\":\"https://openai.github.io/openai-agents-python/\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>Title: OpenAI Agents SDK\n",
       "\n",
       "URL Source: https://openai.github.io/openai-agents-python/\n",
       "\n",
       "Published Time: Fri, 31 Oct 2025 05:48:14 GMT\n",
       "\n",
       "Markdown Content:\n",
       "OpenAI Agents SDK\n",
       "\n",
       "===============\n",
       "- [x] - [x] \n",
       "\n",
       "[Skip to content](https://openai.github.io/openai-agents-python/#openai-agents-sdk)\n",
       "\n",
       "[![Image 1: logo](https://openai.github.io/openai-agents-python/assets/logo.svg)](https://openai.github.io/openai-agents-python/ \"OpenAI Agents SDK\")\n",
       "\n",
       " OpenAI Agents SDK \n",
       "\n",
       " Intro \n",
       "\n",
       "*   [English](https://openai.github.io/openai-agents-python/)\n",
       "*   [日本語](https://openai.github.io/openai-agents-python/ja/)\n",
       "*   [한국어](https://openai.github.io/openai-agents-python/ko/)\n",
       "*   [简体中文](https://openai.github.io/openai-agents-python/zh/)\n",
       "\n",
       " Initializing search \n",
       "\n",
       "[openai-agents-python * v0.4.2 * 17k * 2.8k](https://github.com/openai/openai-agents-python \"Go to repository\")\n",
       "\n",
       "[![Image 2: logo](https://openai.github.io/openai-agents-python/assets/logo.svg)](https://openai.github.io/openai-agents-python/ \"OpenAI Agents SDK\") OpenAI Agents SDK  \n",
       "\n",
       "[openai-agents-python * v0.4.2 * 17k * 2.8k](https://github.com/openai/openai-agents-python \"Go to repository\")\n",
       "\n",
       "*   - [x]  Intro  [Intro](https://openai.github.io/openai-agents-python/) Table of contents  \n",
       "    *   [Why use the Agents SDK](https://openai.github.io/openai-agents-python/#why-use-the-agents-sdk)\n",
       "    *   [Installation](https://openai.github.io/openai-agents-python/#installation)\n",
       "    *   [Hello world example](https://openai.github.io/openai-agents-python/#hello-world-example)\n",
       "\n",
       "*   [Quickstart](https://openai.github.io/openai-agents-python/quickstart/)\n",
       "*   [Examples](https://openai.github.io/openai-agents-python/examples/)\n",
       "*   - [x]  Documentation   Documentation  \n",
       "    *   [Agents](https://openai.github.io/openai-agents-python/agents/)\n",
       "    *   [Running agents](https://openai.github.io/openai-agents-python/running_agents/)\n",
       "    *   - [x]  Sessions   Sessions  \n",
       "        *   [Sessions](https://openai.github.io/openai-agents-python/sessions/)\n",
       "        *   [SQLAlchemy Sessions](https://openai.github.io/openai-agents-python/sessions/sqlalchemy_session/)\n",
       "        *   [Advanced SQLite Sessions](https://openai.github.io/openai-agents-python/sessions/advanced_sqlite_session/)\n",
       "        *   [Encrypted Sessions](https://openai.github.io/openai-agents-python/sessions/encrypted_session/)\n",
       "\n",
       "    *   [Results](https://openai.github.io/openai-agents-python/results/)\n",
       "    *   [Streaming](https://openai.github.io/openai-agents-python/streaming/)\n",
       "    *   [REPL utility](https://openai.github.io/openai-agents-python/repl/)\n",
       "    *   [Tools](https://openai.github.io/openai-agents-python/tools/)\n",
       "    *   [Model context protocol (MCP)](https://openai.github.io/openai-agents-python/mcp/)\n",
       "    *   [Handoffs](https://openai.github.io/openai-agents-python/handoffs/)\n",
       "    *   [Tracing](https://openai.github.io/openai-agents-python/tracing/)\n",
       "    *   [Context management](https://openai.github.io/openai-agents-python/context/)\n",
       "    *   [Guardrails](https://openai.github.io/openai-agents-python/guardrails/)\n",
       "    *   [Orchestrating multiple agents](https://openai.github.io/openai-agents-python/multi_agent/)\n",
       "    *   [Usage](https://openai.github.io/openai-agents-python/usage/)\n",
       "    *   - [x]  Models   Models  \n",
       "        *   [Models](https://openai.github.io/openai-agents-python/models/)\n",
       "        *   [Using any model via LiteLLM](https://openai.github.io/openai-agents-python/models/litellm/)\n",
       "\n",
       "    *   [Configuring the SDK](https://openai.github.io/openai-agents-python/config/)\n",
       "    *   [Agent Visualization](https://openai.github.io/openai-agents-python/visualization/)\n",
       "    *   [Release process/changelog](https://openai.github.io/openai-agents-python/release/)\n",
       "    *   - [x]  Voice agents   Voice agents  \n",
       "        *   [Quickstart](https://openai.github.io/openai-agents-python/voice/quickstart/)\n",
       "        *   [Pipelines and workflows](https://openai.github.io/openai-agents-python/voice/pipeline/)\n",
       "        *   [Tracing](https://openai.github.io/openai-agents-python/voice/tracing/)\n",
       "\n",
       "    *   - [x]  Realtime agents   Realtime agents  \n",
       "        *   [Quickstart](https://openai.github.io/openai-agents-python/realtime/quickstart/)\n",
       "        *   [Guide](https://openai.github.io/openai-agents-python/realtime/guide/)\n",
       "\n",
       "*   - [x]  API Reference   API Reference  \n",
       "    *   - [x]  Agents   Agents  \n",
       "        *   [Agents module](https://openai.github.io/openai-agents-python/ref/)\n",
       "        *   [Agents](https://openai.github.io/openai-agents-python/ref/agent/)\n",
       "        *   [Runner](https://openai.github.io/openai-agents-python/ref/run/)\n",
       "        *   [Memory](https://openai.github.io/openai-agents-python/ref/memory/)\n",
       "        *   [repl](https://openai.github.io/openai-agents-python/ref/repl/)\n",
       "        *   [Tools](https://openai.github.io/openai-agents-python/ref/tool/)\n",
       "        *   [Tool Context](https://openai.github.io/openai-agents-python/ref/tool_context/)\n",
       "        *   [Results](https://openai.github.io/openai-agents-python/ref/result/)\n",
       "        *   [Streaming events](https://openai.github.io/openai-agents-python/ref/stream_events/)\n",
       "        *   [Handoffs](https://openai.github.io/openai-agents-python/ref/handoffs/)\n",
       "        *   [Lifecycle](https://openai.github.io/openai-agents-python/ref/lifecycle/)\n",
       "        *   [Items](https://openai.github.io/openai-agents-python/ref/items/)\n",
       "        *   [Run context](https://openai.github.io/openai-agents-python/ref/run_context/)\n",
       "        *   [Tool Context](https://openai.github.io/openai-agents-python/ref/tool_context/)\n",
       "        *   [Usage](https://openai.github.io/openai-agents-python/ref/usage/)\n",
       "        *   [Exceptions](https://openai.github.io/openai-agents-python/ref/exceptions/)\n",
       "        *   [Guardrails](https://openai.github.io/openai-agents-python/ref/guardrail/)\n",
       "        *   [Model settings](https://openai.github.io/openai-agents-python/ref/model_settings/)\n",
       "        *   [Agent output](https://openai.github.io/openai-agents-python/ref/agent_output/)\n",
       "        *   [Function schema](https://openai.github.io/openai-agents-python/ref/function_schema/)\n",
       "        *   [Model interface](https://openai.github.io/openai-agents-python/ref/models/interface/)\n",
       "        *   [OpenAI Chat Completions model](https://openai.github.io/openai-agents-python/ref/models/openai_chatcompletions/)\n",
       "        *   [OpenAI Responses model](https://openai.github.io/openai-agents-python/ref/models/openai_responses/)\n",
       "        *   [MCP Servers](https://openai.github.io/openai-agents-python/ref/mcp/server/)\n",
       "        *   [MCP Util](https://openai.github.io/openai-agents-python/ref/mcp/util/)\n",
       "\n",
       "    *   - [x]  Tracing   Tracing  \n",
       "        *   [Tracing module](https://openai.github.io/openai-agents-python/ref/tracing/)\n",
       "        *   [Creating traces/spans](https://openai.github.io/openai-agents-python/ref/tracing/create/)\n",
       "        *   [Traces](https://openai.github.io/openai-agents-python/ref/tracing/traces/)\n",
       "        *   [Spans](https://openai.github.io/openai-agents-python/ref/tracing/spans/)\n",
       "        *   [Processor interface](https://openai.github.io/openai-agents-python/ref/tracing/processor_interface/)\n",
       "        *   [Processors](https://openai.github.io/openai-agents-python/ref/tracing/processors/)\n",
       "        *   [Scope](https://openai.github.io/openai-agents-python/ref/tracing/scope/)\n",
       "        *   [Setup](https://openai.github.io/openai-agents-python/ref/tracing/setup/)\n",
       "        *   [Span data](https://openai.github.io/openai-agents-python/ref/tracing/span_data/)\n",
       "        *   [Util](https://openai.github.io/openai-agents-python/ref/tracing/util/)\n",
       "\n",
       "    *   - [x]  Realtime   Realtime  \n",
       "        *   [RealtimeAgent](https://openai.github.io/openai-agents-python/ref/realtime/agent/)\n",
       "        *   [RealtimeRunner](https://openai.github.io/openai-agents-python/ref/realtime/runner/)\n",
       "        *   [RealtimeSession](https://openai.github.io/openai-agents-python/ref/realtime/session/)\n",
       "        *   [Realtime Events](https://openai.github.io/openai-agents-python/ref/realtime/events/)\n",
       "        *   [Realtime Configuration](https://openai.github.io/openai-agents-python/ref/realtime/config/)\n",
       "        *   [Model](https://openai.github.io/openai-agents-python/ref/realtime/model/)\n",
       "\n",
       "    *   - [x]  Voice   Voice  \n",
       "        *   [Pipeline](https://openai.github.io/openai-agents-python/ref/voice/pipeline/)\n",
       "        *   [Workflow](https://openai.github.io/openai-agents-python/ref/voice/workflow/)\n",
       "        *   [Input](https://openai.github.io/openai-agents-python/ref/voice/input/)\n",
       "        *   [Result](https://openai.github.io/openai-agents-python/ref/voice/result/)\n",
       "        *   [Pipeline Config](https://openai.github.io/openai-agents-python/ref/voice/pipeline_config/)\n",
       "        *   [Events](https://openai.github.io/openai-agents-python/ref/voice/events/)\n",
       "        *   [Exceptions](https://openai.github.io/openai-agents-python/ref/voice/exceptions/)\n",
       "        *   [Model](https://openai.github.io/openai-agents-python/ref/voice/model/)\n",
       "        *   [Utils](https://openai.github.io/openai-agents-python/ref/voice/utils/)\n",
       "        *   [OpenAIVoiceModelProvider](https://openai.github.io/openai-agents-python/ref/voice/models/openai_provider/)\n",
       "        *   [OpenAI STT](https://openai.github.io/openai-agents-python/ref/voice/models/openai_stt/)\n",
       "        *   [OpenAI TTS](https://openai.github.io/openai-agents-python/ref/voice/models/openai_tts/)\n",
       "\n",
       "    *   - [x]  Extensions   Extensions  \n",
       "        *   [Handoff filters](https://openai.github.io/openai-agents-python/ref/extensions/handoff_filters/)\n",
       "        *   [Handoff prompt](https://openai.github.io/openai-agents-python/ref/extensions/handoff_prompt/)\n",
       "        *   [LiteLLM Models](https://openai.github.io/openai-agents-python/ref/extensions/litellm/)\n",
       "        *   [SQLAlchemySession](https://openai.github.io/openai-agents-python/ref/extensions/memory/sqlalchemy_session/)\n",
       "        *   [EncryptedSession](https://openai.github.io/openai-agents-python/ref/extensions/memory/encrypt_session/)\n",
       "        *   [AdvancedSQLiteSession](https://openai.github.io/openai-agents-python/ref/extensions/memory/advanced_sqlite_session/)\n",
       "\n",
       " Table of contents  \n",
       "*   [Why use the Agents SDK](https://openai.github.io/openai-agents-python/#why-use-the-agents-sdk)\n",
       "*   [Installation](https://openai.github.io/openai-agents-python/#installation)\n",
       "*   [Hello world example](https://openai.github.io/openai-agents-python/#hello-world-example)\n",
       "\n",
       "OpenAI Agents SDK\n",
       "=================\n",
       "\n",
       "The [OpenAI Agents SDK](https://github.com/openai/openai-agents-python) enables you to build agentic AI apps in a lightweight, easy-to-use package with very few abstractions. It's a production-ready upgrade of our previous experimentation for agents, [Swarm](https://github.com/openai/swarm/tree/main). The Agents SDK has a very small set of primitives:\n",
       "\n",
       "*   **Agents**, which are LLMs equipped with instructions and tools\n",
       "*   **Handoffs**, which allow agents to delegate to other agents for specific tasks\n",
       "*   **Guardrails**, which enable validation of agent inputs and outputs\n",
       "*   **Sessions**, which automatically maintains conversation history across agent runs\n",
       "\n",
       "In combination with Python, these primitives are powerful enough to express complex relationships between tools and agents, and allow you to build real-world applications without a steep learning curve. In addition, the SDK comes with built-in **tracing** that lets you visualize and debug your agentic flows, as well as evaluate them and even fine-tune models for your application.\n",
       "\n",
       "Why use the Agents SDK\n",
       "----------------------\n",
       "\n",
       "The SDK has two driving design principles:\n",
       "\n",
       "1.   Enough features to be worth using, but few enough primitives to make it quick to learn.\n",
       "2.   Works great out of the box, but you can customize exactly what happens.\n",
       "\n",
       "Here are the main features of the SDK:\n",
       "\n",
       "*   Agent loop: Built-in agent loop that handles calling tools, sending results to the LLM, and looping until the LLM is done.\n",
       "*   Python-first: Use built-in language features to orchestrate and chain agents, rather than needing to learn new abstractions.\n",
       "*   Handoffs: A powerful feature to coordinate and delegate between multiple agents.\n",
       "*   Guardrails: Run input validations and checks in parallel to your agents, breaking early if the checks fail.\n",
       "*   Sessions: Automatic conversation history management across agent runs, eliminating manual state handling.\n",
       "*   Function tools: Turn any Python function into a tool, with automatic schema generation and Pydantic-powered validation.\n",
       "*   Tracing: Built-in tracing that lets you visualize, debug and monitor your workflows, as well as use the OpenAI suite of evaluation, fine-tuning and distillation tools.\n",
       "\n",
       "Installation\n",
       "------------\n",
       "\n",
       "```\n",
       "pip install openai-agents\n",
       "```\n",
       "\n",
       "Hello world example\n",
       "-------------------\n",
       "\n",
       "```\n",
       "from agents import Agent, Runner\n",
       "\n",
       "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
       "\n",
       "result = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\n",
       "print(result.final_output)\n",
       "\n",
       "# Code within the code,\n",
       "# Functions calling themselves,\n",
       "# Infinite loop's dance.\n",
       "```\n",
       "\n",
       "(_If running this, ensure you set the `OPENAI\\_API\\_KEY` environment variable_)\n",
       "\n",
       "```\n",
       "export OPENAI_API_KEY=sk-...\n",
       "```\n",
       "</pre>\n",
       "            </div>\n",
       "\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The <strong>OpenAI Agents SDK</strong> is a tool designed to help developers create AI applications that revolve around agent-based models. Here are some of its main features and functionalities:</p>\n",
       "<h3>Overview</h3>\n",
       "<ul>\n",
       "<li><strong>Purpose</strong>: It enables the building of AI agents that can perform tasks through a lightweight and user-friendly interface.</li>\n",
       "<li><strong>Core Elements</strong>:<ul>\n",
       "<li><strong>Agents</strong>: LLMs (Large Language Models) equipped with specific instructions and tools.</li>\n",
       "<li><strong>Handoffs</strong>: Mechanisms for agents to delegate tasks to other agents.</li>\n",
       "<li><strong>Guardrails</strong>: Validation tools for ensuring the integrity of inputs and outputs.</li>\n",
       "<li><strong>Sessions</strong>: Features that automatically manage conversation history.</li>\n",
       "</ul>\n",
       "</li>\n",
       "</ul>\n",
       "<h3>Key Features</h3>\n",
       "<ol>\n",
       "<li><strong>Agent Loop</strong>: Facilitates the iterative calling of tools and processing results from LLMs.</li>\n",
       "<li><strong>Python-first Design</strong>: Uses native Python features for orchestration, making it easier to learn and implement.</li>\n",
       "<li><strong>Handoffs</strong>: Supports coordination among multiple agents.</li>\n",
       "<li><strong>Guardrails</strong>: Enables real-time input validation to prevent erroneous outputs.</li>\n",
       "<li><strong>Automatic Session Management</strong>: Keeps track of conversation history seamlessly.</li>\n",
       "<li><strong>Function Tools</strong>: Allows any Python function to be transformed into a tool with automatic validation.</li>\n",
       "<li><strong>Tracing</strong>: Built-in tracing capabilities for visualizing and debugging agent flows.</li>\n",
       "</ol>\n",
       "<h3>Installation and Usage</h3>\n",
       "<p>To install the SDK, you can use the command:</p>\n",
       "<pre><code class=\"language-bash\">pip install openai-agents\n",
       "</code></pre>\n",
       "<h3>Example Code</h3>\n",
       "<p>A simple example to use the SDK:</p>\n",
       "<pre><code class=\"language-python\">from agents import Agent, Runner\n",
       "\n",
       "agent = Agent(name=&quot;Assistant&quot;, instructions=&quot;You are a helpful assistant&quot;)\n",
       "result = Runner.run_sync(agent, &quot;Write a haiku about recursion in programming.&quot;)\n",
       "print(result.final_output)\n",
       "</code></pre>\n",
       "<p>This SDK is particularly useful for developers looking to create complex AI solutions without extensive technical overhead. It combines ease of use with powerful capabilities for agent-based applications. For more details, you can visit the <a href=\"https://openai.github.io/openai-agents-python/\">official documentation</a>.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: what are agents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>In the context of the <strong>OpenAI Agents SDK</strong>, <strong>agents</strong> refer to specialized AI entities built using Large Language Models (LLMs) that are designed to perform specific tasks. Here are some key characteristics and functionalities of agents:</p>\n",
       "<h3>Key Characteristics of Agents</h3>\n",
       "<ol>\n",
       "<li><p><strong>Purposeful Behavior</strong>: Agents are created with specific instructions to fulfill particular roles or tasks, making them purposeful in their actions.</p>\n",
       "</li>\n",
       "<li><p><strong>Equipped with Tools</strong>: They can utilize various tools and resources to carry out their instructions, which can include calling other functions or interacting with external APIs.</p>\n",
       "</li>\n",
       "<li><p><strong>Autonomous Decision-Making</strong>: Agents can make decisions based on their internal logic and instructions, allowing them to respond dynamically to user inputs or environmental changes.</p>\n",
       "</li>\n",
       "<li><p><strong>Session Management</strong>: Agents can maintain a conversation history across interactions, allowing for more coherent and contextually aware responses in multi-turn dialogs.</p>\n",
       "</li>\n",
       "<li><p><strong>Handoffs</strong>: They can delegate tasks to other agents as needed, facilitating more complex operations that may require collaboration between multiple entities.</p>\n",
       "</li>\n",
       "<li><p><strong>Guardrails</strong>: Agents are equipped with validation mechanisms to check their inputs and outputs, ensuring the quality and safety of their interactions.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<h3>Examples of Agent Use Cases</h3>\n",
       "<ul>\n",
       "<li><strong>Customer Support</strong>: An agent can be designed to answer customer inquiries, manage support tickets, and provide information about products or services.</li>\n",
       "<li><strong>Content Generation</strong>: Agents can create articles, social media posts, or other written content based on given themes or instructions.</li>\n",
       "<li><strong>Task Automation</strong>: They can automate routines such as scheduling meetings or managing workflows based on user needs.</li>\n",
       "</ul>\n",
       "<p>Overall, agents in the SDK act as versatile AI assistants capable of handling a variety of tasks with intelligence and efficiency. They enable developers to build applications that require a level of autonomy and decision-making capability.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "await runner.run();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505951c-501c-41fb-abd2-202641fbe328",
   "metadata": {},
   "source": [
    "### Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4702c25-ce91-4a64-933a-494ad9e27ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def format_timestamp(seconds:float) -> str:\n",
    "    \"\"\"Convert seconds to H:MM:SS if > 1hour, else M:SS\"\"\"\n",
    "    total_seconds = int(seconds)\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes,secs = divmod(remainder, 60)\n",
    "\n",
    "    if hours>0:\n",
    "        return f\"{hours}:{minutes:02}:{secs:02}\"\n",
    "    else:\n",
    "        return f\"{minutes}:{secs:02}\"\n",
    "\n",
    "def make_subtitles (transcript) ->str:\n",
    "    lines=[]\n",
    "\n",
    "    for entry in transcript:\n",
    "        ts = format_timestamp(entry.start)\n",
    "        text = entry.text.replace('\\n',' ')\n",
    "        lines.append(ts+' '+text)\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def fetch_transcript_raw(video_id):\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "    transcript = ytt_api.fetch(video_id)\n",
    "    return transcript\n",
    "\n",
    "def fetch_transcript_text(video_id):\n",
    "    transcript = fetch_transcript_raw(video_id)\n",
    "    subtitles = make_subtitles(transcript)\n",
    "    return subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9e07e62-9919-4d2c-943a-99af14605a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def fetch_transcript_cached(video_id):\n",
    "    cache_dir = Path(\"./_import/src/data_cache/youtube_videos\")\n",
    "    cache_file = cache_dir / f\"{video_id}.txt\"\n",
    "\n",
    "    if cache_file.exists():\n",
    "        return cache_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    subtitles = fetch_transcript_text(video_id)\n",
    "    cache_file.write_text(subtitles, encoding=\"utf-8\")\n",
    "\n",
    "    return subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab41c47c-6a29-4ff6-8563-1e0f883f581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id='bwfR9dyxf1M'\n",
    "cache_dir = Path(\"./_import/src/data_cache/youtube_videos\")\n",
    "cache_file = cache_dir / f\"{video_id}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec1b42cb-04e9-4abd-a997-e3dd4992d0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('_import/src/data_cache/youtube_videos/bwfR9dyxf1M.txt')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc6e3d1f-bee3-44b0-87b4-ec03e8b7d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHubDoc.ipynb  _import\t   docs.py\n",
      "__pycache__\t agenticrag.ipynb  webyoutube.ipynb\n"
     ]
    }
   ],
   "source": [
    "fetch_transcript_cached("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "780ac0d4-b144-4f1d-b341-2641ccbfd159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00 Hey everyone, welcome to our event. This\n",
      "0:02 event is brought to you by data talks\n",
      "0:03 club which is a community of people who\n",
      "0:05 love data. We have weekly events today.\n",
      "0:08 Uh this is one of such events. Um if you\n",
      "0:11 want to find out more about the events\n",
      "0:13 we have, there is a link in the\n",
      "0:14 description. Um so click on that link,\n",
      "0:16 check it out right now. We actually have\n",
      "0:19 quite a few events in our pipeline, but\n",
      "0:21 we need to put them on the website. Uh\n",
      "0:24 but keep a\n"
     ]
    }
   ],
   "source": [
    "transcript = fetch_youtube_transcript('vK_SxyqIfwk')\n",
    "print(transcript[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaa19c6f-08c2-4b45-b450-7b4999b612f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_youtube_transcript(video_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the transcript of a YouTube video and converts it into a subtitle-formatted string.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): The unique YouTube video ID.\n",
    "\n",
    "    Returns:\n",
    "        str: The subtitles generated from the video's transcript.\n",
    "    \"\"\"\n",
    "    return fetch_transcript_cached(video_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ab76317-21cc-487b-b3fe-5c00e7169f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_instructions = \"\"\"\n",
    "You're a helpful assistant that helps answer user questions\n",
    "about YouTube videos\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "    function_tool(fetch_youtube_transcript)\n",
    "]\n",
    "\n",
    "youtube_assistant = Agent(\n",
    "    name='youtube_assistant',\n",
    "    tools=tools,\n",
    "    instructions=summary_instructions,\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48225478-9284-46b1-908b-0521012f78c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: summarize the youtube video vK_SxyqIfwk'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>fetch_youtube_transcript({\"video_id\":\"vK_SxyqIfwk\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"video_id\":\"vK_SxyqIfwk\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>0:00 Hey everyone, welcome to our event. This\n",
       "0:02 event is brought to you by data talks\n",
       "0:03 club which is a community of people who\n",
       "0:05 love data. We have weekly events today.\n",
       "0:08 Uh this is one of such events. Um if you\n",
       "0:11 want to find out more about the events\n",
       "0:13 we have, there is a link in the\n",
       "0:14 description. Um so click on that link,\n",
       "0:16 check it out right now. We actually have\n",
       "0:19 quite a few events in our pipeline, but\n",
       "0:21 we need to put them on the website. Uh\n",
       "0:24 but keep an eye on it anyways. Um so we\n",
       "0:27 will put um them. you'll see them. And\n",
       "0:30 then don't forget to subscribe to our\n",
       "0:32 YouTube channel. So this is the most um\n",
       "0:35 reliable way of getting notified when\n",
       "0:37 our stream starts. And last but not\n",
       "0:40 least, do not forget to join our um data\n",
       "0:43 community where you can hang out with\n",
       "0:45 data with other data enthusiasts. During\n",
       "0:48 today's interview, you can ask any\n",
       "0:49 question you want. There is a pinned\n",
       "0:51 link in the live chat. Click on that\n",
       "0:53 link, ask your questions and we'll be\n",
       "0:56 covering your questions during the\n",
       "0:58 interview. So that's the usual\n",
       "1:01 introduction I do.\n",
       "1:04 Also, I'm a bit sleepy. Um, but I hope\n",
       "1:07 it goes well.\n",
       "1:10 So I guess if you're ready, I have the\n",
       "1:13 questions prepared\n",
       "1:16 in front of me.\n",
       "1:17 Yeah,\n",
       "1:18 if you're ready, we can start.\n",
       "1:20 Yeah, sounds good. Ready? Um, today on\n",
       "1:24 the podcast we are joined by Aishwara.\n",
       "1:26 Do you pronounce your name correctly?\n",
       "1:28 Yes, that is right.\n",
       "1:29 Yeah, good. A machine learning engineer\n",
       "1:32 at Vimo, formerly part of Tesla's\n",
       "1:34 autopilot AI team and a Cambridge Melon\n",
       "1:36 University Alumni. Aishwara has worked\n",
       "1:39 across some of the toughest applied AI\n",
       "1:42 problems. Financial recommendation\n",
       "1:44 systems at Morgan Stanley, multimodel\n",
       "1:46 research at CMU, perception and video\n",
       "1:49 understanding and Tesla and now gesture\n",
       "1:51 and pedestrial semantics at IMA. She has\n",
       "1:54 also contributed to AI for social good\n",
       "1:56 including a malaria mapping project in\n",
       "1:58 Africa that achieved real world impact\n",
       "2:00 at scale.\n",
       "2:02 Welcome to this event.\n",
       "2:06 Hi, thank you for having me. Yeah,\n",
       "2:09 that's um quite a nice bio. Um\n",
       "2:12 especially um I don't know probably\n",
       "2:16 um what you do now uh at and Tesla\n",
       "2:19 is challenging but for me also Morgan\n",
       "2:22 Stanley sounds very challenging cuz um I\n",
       "2:26 worked a little near high frequency\n",
       "2:29 trading. So I wasn't actually working on\n",
       "2:32 the system that we were doing tra uh\n",
       "2:33 high frequency trading but we were doing\n",
       "2:36 some um\n",
       "2:38 how to say analytics on top of this\n",
       "2:40 data. It was huge. So probably quite\n",
       "2:44 challenging. Um so can you tell us uh I\n",
       "2:48 just outlined your uh career journey but\n",
       "2:51 can you tell us more about this? Um\n",
       "2:55 yeah uh so I I think uh like you\n",
       "2:58 mentioned at Morgan Stanley it was a lot\n",
       "3:01 of data. So I was a big data engineer at\n",
       "3:03 Morgan Stanley and I basically did that\n",
       "3:06 handle all this huge amounts of data and\n",
       "3:10 I was there when Morgan Stanley you know\n",
       "3:12 they were doing this acquisition of\n",
       "3:14 Erade. So we had like a lot more data\n",
       "3:16 coming in. So my role there was you know\n",
       "3:19 handling all this data. How do we\n",
       "3:21 connect the different dots? how do we\n",
       "3:22 analyze them together? And from there I\n",
       "3:26 uh like realized that you know there's\n",
       "3:29 so much of data that it has so much of\n",
       "3:30 value that we don't need to do all the\n",
       "3:33 things that we do manually and that was\n",
       "3:35 back I guess in 2018 and the whole AI\n",
       "3:39 domain the AI bubble hadn't like formed\n",
       "3:41 yet but you know it was getting there\n",
       "3:43 people were realizing how important it\n",
       "3:45 was and uh finance was one of the last\n",
       "3:48 fields to take on uh the machine\n",
       "3:50 learning aspect the AI aspect so we were\n",
       "3:53 onboarding systems And that's when I\n",
       "3:55 decided to like you know get a hand at\n",
       "3:58 it and like try some of like begin with\n",
       "4:00 some of the smaller systems like you\n",
       "4:02 know recommendation engines and uh stuff\n",
       "4:05 that was already well known in the uh AI\n",
       "4:09 domain. So I started off as that and\n",
       "4:12 then we decided to get a bit more uh I\n",
       "4:16 guess researchy with that. We tried out\n",
       "4:18 like you know graph neural networks\n",
       "4:20 which were some of the more complicated\n",
       "4:22 topics at that point and that's when I\n",
       "4:24 realized that oh it's you know there's\n",
       "4:26 so much to be learned here and there's\n",
       "4:28 so many this this field is so vast so\n",
       "4:30 that's when I decided to like uh pursue\n",
       "4:33 a masters\n",
       "4:34 and I like decided to join Kangi Melon\n",
       "4:37 University and my program it was like\n",
       "4:41 sorry it was a mix of data science and\n",
       "4:44 uh machine learning so I had like I\n",
       "4:46 could draw upon both my experiences and\n",
       "4:48 what I wanted to learn and where I\n",
       "4:50 wanted to get at and dur during CMU I\n",
       "4:53 was more like uh inclined towards\n",
       "4:56 projects that involved a lot of computer\n",
       "4:58 vision. So I was involved in this\n",
       "5:00 project project for like navigational\n",
       "5:03 app for blind people. Uh so it's called\n",
       "5:06 like AI guide dog. So it it like takes\n",
       "5:09 in the world and navigates uh people\n",
       "5:11 without vision. And from there, you\n",
       "5:14 know, I got into Tesla because it's also\n",
       "5:16 similar like computer vision domain and\n",
       "5:18 navigation related stuff. Uh and that's\n",
       "5:21 where my self-driving journey began. And\n",
       "5:23 then from Tesla to Wayob, it's like a\n",
       "5:26 similar domain but uh different kinds of\n",
       "5:28 products. Uh like uh some different like\n",
       "5:31 differences are there. Uh and yeah, uh\n",
       "5:34 that's where I am at Whimo right now. um\n",
       "5:37 in the self-driving domain started from\n",
       "5:39 finance uh reached in a different domain\n",
       "5:42 but yeah\n",
       "5:43 that's that's an interesting journey uh\n",
       "5:45 this app that you developed for blind\n",
       "5:48 people\n",
       "5:49 um can you tell us more about it like\n",
       "5:52 how does it work uh is it uh like they\n",
       "5:55 hold their phone and then it tells uh\n",
       "5:57 where to go or describes things\n",
       "6:01 yeah sorry\n",
       "6:03 so yeah for this uh app like the goal\n",
       "6:06 was that you know uh people without\n",
       "6:08 vision they should be able to navigate\n",
       "6:10 the world just as cited people do. So\n",
       "6:13 this app is basically their eyes. So it\n",
       "6:16 you just like hang it around your neck\n",
       "6:18 and you walk with it and it gets a world\n",
       "6:21 view of what is in front of you and then\n",
       "6:24 uh via like live audio instructions. It\n",
       "6:27 tells you like you know keep walking\n",
       "6:29 straight and uh if you've entered a\n",
       "6:31 destination based on that you know take\n",
       "6:33 left or right or stop at a traffic\n",
       "6:35 signal or there's like you know\n",
       "6:36 pedestrian crossings so it gives you\n",
       "6:39 instructions via audio.\n",
       "6:41 Interesting. And is it something you did\n",
       "6:44 just as a pet project? Was it a part of\n",
       "6:46 a company? Was it AI for social good\n",
       "6:49 project? How did you\n",
       "6:52 um get involved?\n",
       "6:53 Yeah. So uh so my program has this uh\n",
       "6:57 thing called the capstone project. So\n",
       "6:58 every year like you either pair up with\n",
       "7:01 a professor or someone from the industry\n",
       "7:03 who already has a very interesting\n",
       "7:05 project and then you work on it. So this\n",
       "7:08 project was from an alumni uh of CMU and\n",
       "7:11 he currently works at Pinterest. Uh but\n",
       "7:14 he started this whole project and uh\n",
       "7:16 this was like the third iteration where\n",
       "7:18 you know he worked with two groups of\n",
       "7:19 folks before and then uh my team on\n",
       "7:22 boarded on it. Mhm. Okay. But was it um\n",
       "7:26 like a community AI social good project\n",
       "7:29 or was it a company?\n",
       "7:32 Um I would say it was like more of a\n",
       "7:35 volunteer project. So uh it's it's just\n",
       "7:39 like they every year a group of\n",
       "7:41 volunteers from CMU work on it and then\n",
       "7:45 we make some progress and then we pass\n",
       "7:46 it on to the next group.\n",
       "7:48 That's a very interesting concept.\n",
       "7:51 Yeah. So before me like two batches of\n",
       "7:53 people had worked on it. So they were\n",
       "7:55 like mentors to us and then when I got\n",
       "7:57 done I mentored another batch that came\n",
       "8:00 after me. So this is like in its fifth\n",
       "8:02 iteration now like there have been two\n",
       "8:04 batches after me and they are making\n",
       "8:06 more and more progress on this print.\n",
       "8:09 That's really\n",
       "8:12 that's a really nice idea because well\n",
       "8:15 we have courses at data talks club and\n",
       "8:17 for me I immediately uh started thinking\n",
       "8:21 how can I implement something like this\n",
       "8:22 cuz it sounds so amazing and with the\n",
       "8:25 community we have uh I see that the\n",
       "8:28 people from the uh previous iterations\n",
       "8:30 they have people who are currently doing\n",
       "8:32 courses. So having a project like that\n",
       "8:35 for them to actually um sharpen the\n",
       "8:38 skills they picked up during the courses\n",
       "8:40 that's a really good idea.\n",
       "8:42 Yeah. And it doesn't need to be like you\n",
       "8:44 know done like it's a big thing right?\n",
       "8:46 You need there's so many moving\n",
       "8:48 components. It can't be built in one\n",
       "8:50 year by a given cohort or even in 6\n",
       "8:52 months by a given cohort. So you like\n",
       "8:55 pick up small pieces like the first one\n",
       "8:57 started with like the data efforts. The\n",
       "8:59 second one started building like\n",
       "9:00 baseline models. the third one like\n",
       "9:02 tried improving it with evals and stuff.\n",
       "9:05 So you do it iteratively.\n",
       "9:07 So it's a good idea. Yeah.\n",
       "9:09 Do do you know if this app is accessible\n",
       "9:11 uh in app store?\n",
       "9:14 Uh not yet. So the the next community\n",
       "9:17 like the new batch of students are going\n",
       "9:19 to be working on the app. We have the\n",
       "9:21 model but it's still in beta phase. Uh\n",
       "9:24 we are doing a lot of testing because\n",
       "9:26 it's kind of like a sensitive use case\n",
       "9:28 and uh yeah.\n",
       "9:29 Yeah. Yeah. You can imagine I recently\n",
       "9:32 uh participated in a marathon. People\n",
       "9:35 who know me, they would roll their eyes\n",
       "9:36 cuz I wouldn't shut up. Of course, I've\n",
       "9:38 been preparing for so long. Uh but yeah,\n",
       "9:41 so the reason I thought about this uh\n",
       "9:44 blind people also or people with um\n",
       "9:48 how to say um with vision problems and\n",
       "9:52 also completely blind who don't see at\n",
       "9:55 all. They took part in this but they\n",
       "9:57 were running with a guide. So there was\n",
       "9:58 a person who was running with them and\n",
       "10:00 they were holding their hands uh and\n",
       "10:03 running together\n",
       "10:04 and I thought like it's so amazing to\n",
       "10:08 include them too like cuz they also want\n",
       "10:10 to be a part of this event but cuz they\n",
       "10:12 cannot see it's very difficult but what\n",
       "10:16 they did uh they allowed um they called\n",
       "10:20 them guides to also join and be the\n",
       "10:23 leads and this is so amazing and I guess\n",
       "10:26 well maybe with this app they wouldn't\n",
       "10:28 be able to run an event, a race. Uh but\n",
       "10:33 uh yeah, this is one step closer to\n",
       "10:37 this, right?\n",
       "10:38 Yeah, we that that's the hope like you\n",
       "10:40 know, they don't need like uh a person\n",
       "10:43 or some rely on someone. They can just\n",
       "10:45 have their app and that can be their\n",
       "10:47 guide for the world. Yeah. Mhm. And also\n",
       "10:50 with this um VR glasses um you probably\n",
       "10:55 heard like I think Meta has them, some\n",
       "10:57 other companies have them. So you put\n",
       "10:59 them in your eyes and they uh have\n",
       "11:02 cameras, right? And the cameras they\n",
       "11:05 have broader,\n",
       "11:08 how to say vision than mobile phones.\n",
       "11:12 Yeah. Yes.\n",
       "11:12 Right. So maybe\n",
       "11:15 Yeah. Maybe this is something that um\n",
       "11:18 future alumni can work on, right?\n",
       "11:22 Or like\n",
       "11:27 cars, right? Not necessarily cameras.\n",
       "11:30 Yeah, that's like, you know, those are\n",
       "11:32 the things that we're trying to work\n",
       "11:33 around because it needs to be cost\n",
       "11:35 efficient and you know, we can't afford\n",
       "11:36 to put like lighters and stuff. So, a\n",
       "11:38 mobile phone, everyone has it like in\n",
       "11:41 today's world. So, we're trying to fit\n",
       "11:42 it on what everyone has. How expensive\n",
       "11:46 is uh uh lit lighter?\n",
       "11:50 I think it depends on the quality like\n",
       "11:52 uh you can get from somewhere like\n",
       "11:55 really cheap to extremely high-end. Uh\n",
       "11:58 so yeah, I guess the\n",
       "12:00 pronounce it lighter. LAR\n",
       "12:03 it's LAR. Yeah,\n",
       "12:04 LAR. So this is I know radar. So radar\n",
       "12:08 emits uh uh radio frequencies and one\n",
       "12:12 waits back to the frequency to come back\n",
       "12:14 to the wave to come back right and based\n",
       "12:17 on that uh the the radar can estimate if\n",
       "12:21 there's something\n",
       "12:24 uh and if it's moving\n",
       "12:26 uh and so on. Um whales do this right?\n",
       "12:29 So they make sound\n",
       "12:31 or I don't know maybe not whales but\n",
       "12:33 some other\n",
       "12:35 bats.\n",
       "12:37 Yeah. Yeah.\n",
       "12:39 And the same uh uh the same thing u\n",
       "12:42 lighter has um kind of similar idea but\n",
       "12:46 it's instead of um a radio wave it uses\n",
       "12:50 lasers, right?\n",
       "12:52 Uh it it's light. Yes, that's right.\n",
       "12:55 Like light rays. Yes. Okay.\n",
       "12:57 That's why the lighter thing. Yeah.\n",
       "12:59 Okay. I thought it's laser there. Okay.\n",
       "13:01 Uh similar like I I think it's one of\n",
       "13:03 the light frequencies.\n",
       "13:05 Okay. Okay. And um\n",
       "13:08 I don't know if you can disclose or talk\n",
       "13:11 about things you do at work, but um I\n",
       "13:13 know that these things they are used\n",
       "13:16 often for cars, right? For self-driving.\n",
       "13:21 Yeah. Uh I think it uh like depends on\n",
       "13:23 the stack. Uh some companies they do use\n",
       "13:28 like uh most of the like uh fully\n",
       "13:31 self-driving where there is like\n",
       "13:33 absolutely no driver use it. Uh whereas\n",
       "13:36 if you see some of the Tesla systems,\n",
       "13:38 they do not use it at all. They rely\n",
       "13:40 solely on the cameras. Yeah.\n",
       "13:41 Mhm. So Tesla I um took a few times a\n",
       "13:46 taxi which turned out to be Tesla and\n",
       "13:49 for me it was so fun to watch um they\n",
       "13:52 have this uh screen and as the car\n",
       "13:55 drives they start showing uh like cars\n",
       "13:58 and people and uh stuff like around the\n",
       "14:01 car, right? And uh for me it was always\n",
       "14:04 curious to see like when it makes\n",
       "14:05 mistakes or when it doesn't make\n",
       "14:07 mistakes. Um well but for me it was kind\n",
       "14:10 of fun to watch. So the ride was more\n",
       "14:12 entertaining than a usual I don't know\n",
       "14:15 um Toyota right cuz I could look at the\n",
       "14:20 at the screen.\n",
       "14:22 Um so this thing works with a camera\n",
       "14:24 right\n",
       "14:27 here. Sorry, I've uh I think I came down\n",
       "14:30 with a flu in in the evening. Um yeah,\n",
       "14:34 like I have cold. U might take like\n",
       "14:36 brief.\n",
       "14:36 Hope you recover very quickly.\n",
       "14:40 Yeah. Um sorry. Uh like could you please\n",
       "14:43 quickly repeat the question for me?\n",
       "14:45 Yeah. Yeah. Uh so I was uh talking about\n",
       "14:47 uh these Tesla cars, right? And in Tesla\n",
       "14:50 you there's a screen that shows that\n",
       "14:54 detects people, cars, bikes or whatnot.\n",
       "14:57 Yeah.\n",
       "14:59 Do you know how this thing works? Like\n",
       "15:02 does it use just video cameras?\n",
       "15:05 Yeah.\n",
       "15:07 Uh that's like the USB of Tesla systems\n",
       "15:10 that you know they uh because LAR is\n",
       "15:12 expensive or at least the good quality\n",
       "15:14 ones and uh they want to be like really\n",
       "15:17 scalable. They rely on just cameras. But\n",
       "15:20 it's not just one camera. There's like\n",
       "15:23 uh you know cameras all around the car.\n",
       "15:25 So you get a view from all around like a\n",
       "15:28 360 view of the system and uh you kind\n",
       "15:31 of like run your models on top of it\n",
       "15:33 that can make use of these different\n",
       "15:35 views of the world and see basically all\n",
       "15:38 around the car. So basically the the the\n",
       "15:41 car has a much better holistic view of\n",
       "15:44 the world than a person like a p person\n",
       "15:47 driving the car. Yeah.\n",
       "15:49 Yeah. Cuz we cannot have cameras uh on\n",
       "15:51 our back right on our sides.\n",
       "15:54 Yep. That's yeah.\n",
       "15:56 So yeah, I think that's the goal with\n",
       "15:58 self-driving is to make like driving\n",
       "16:00 safer once it accomplishes that level\n",
       "16:04 of, you know, the the AI reaches that\n",
       "16:06 level. Yeah.\n",
       "16:07 Mhm. But what is this screen for? Like\n",
       "16:10 this screen is for self-driving, right?\n",
       "16:12 But in these cases when I took a taxi,\n",
       "16:14 it was Uber or some other ride hailing\n",
       "16:18 service and they were actually driving.\n",
       "16:22 The drivers were driving, not the car.\n",
       "16:24 So what's the point of this thing?\n",
       "16:27 I think it's more about like at this\n",
       "16:29 point uh so there's two purposes like\n",
       "16:31 you know in like long drives or if the\n",
       "16:33 stop traffic is like stop and go you can\n",
       "16:36 just put it in the autopilot mode and\n",
       "16:37 you don't need to like be constantly on\n",
       "16:40 the wheel and constantly like super\n",
       "16:42 alert and then the car tricks you. Like\n",
       "16:44 I remember 2 years ago I took a trip to\n",
       "16:47 like Vegas. It was like a 13-hour drive\n",
       "16:50 one way and then 13 hours back and I was\n",
       "16:52 the only person driving and like the car\n",
       "16:55 aided me all the way. Like it drove 95%\n",
       "16:57 of the time and I was like just there\n",
       "17:00 and it was so much better because you\n",
       "17:02 know I couldn't have made it without\n",
       "17:03 that like 12 hours is too much.\n",
       "17:05 So it's like an assistant system and\n",
       "17:09 sometimes like people just drive because\n",
       "17:11 they don't trust it. So it's like okay\n",
       "17:14 better me driving than the car doing\n",
       "17:16 something wrong. So it's also about the\n",
       "17:18 trust factor\n",
       "17:18 if there is any statistics about that.\n",
       "17:22 Um there is statistics about like uh\n",
       "17:26 failure. People people are saying that\n",
       "17:28 it's better me driving than AI, right?\n",
       "17:30 Or whatever self-driving thing, but like\n",
       "17:33 the question is who actually drives\n",
       "17:35 better\n",
       "17:37 because people might be overconfident in\n",
       "17:39 their driving skills, right? But for\n",
       "17:41 some simple cases like you said when you\n",
       "17:44 need to go to Vegas, I don't know what\n",
       "17:47 kind of road is there, but maybe it's\n",
       "17:49 like most of the time it's just\n",
       "17:51 straight, right?\n",
       "17:52 Yeah. I I think like uh it's a highway\n",
       "17:55 so it's not like you know there's a lot\n",
       "17:58 of traffic lights and stuff. You just go\n",
       "18:00 straight and you go along the route and\n",
       "18:02 it's like uh there's a there's a patch\n",
       "18:04 which is like just 150 mi straight and\n",
       "18:06 like a normal person would just be so\n",
       "18:08 bored out of their mind if you have to\n",
       "18:10 drive that much.\n",
       "18:13 So, in Berlin, uh it's probably\n",
       "18:15 difficult because there are bikes, uh\n",
       "18:18 the streets are quite narrow, um like\n",
       "18:22 crazy, uh bicycle riders who can jump on\n",
       "18:26 you out of nowhere and um like other\n",
       "18:30 things. I guess that's why they don't\n",
       "18:32 use self.\n",
       "18:34 I think Tesla is trying to get into the\n",
       "18:36 European markets though with its\n",
       "18:38 autopilot. Like at least when I was\n",
       "18:40 trying to like when I was there I was\n",
       "18:42 working on some European road signs like\n",
       "18:45 speed limit signs. So yeah.\n",
       "18:48 Yeah. But also it's regulated, right?\n",
       "18:50 You're right. So maybe they cannot use a\n",
       "18:53 self-driving yet.\n",
       "18:55 Not yet. Yes. Yeah. Yeah.\n",
       "18:56 I see. I see. Makes sense because I am\n",
       "18:59 originally from Russia and I know in\n",
       "19:01 Russia in Moscow some cars already drive\n",
       "19:04 u without drivers. I guess in San\n",
       "19:07 Francisco too, right?\n",
       "19:09 Yes. Yes. SF has SF also has way more\n",
       "19:13 which has like no driver at all. So I\n",
       "19:16 guess very people people are more\n",
       "19:18 interesting.\n",
       "19:19 So you get something like Uber and then\n",
       "19:22 a car comes and there is no driver,\n",
       "19:24 right?\n",
       "19:25 Yes. There's no one there.\n",
       "19:28 If you ever visit if you visit SF next\n",
       "19:31 time, like be sure to take away no. It's\n",
       "19:34 it's quite the tourist attraction right\n",
       "19:36 now over here.\n",
       "19:37 Okay. Okay. Ah, that's where you work,\n",
       "19:39 right?\n",
       "19:40 Yeah. Yeah.\n",
       "19:41 Okay. That's why um is there an app\n",
       "19:44 called Whimo, right?\n",
       "19:46 Yes, there's an app called Whimo through\n",
       "19:48 which you can hail it and I think in\n",
       "19:49 some cities they've also partnered with\n",
       "19:51 Uber and Lyft so that you can call via\n",
       "19:54 Uber as well.\n",
       "19:57 Yeah. How much about your current uh\n",
       "20:00 position can you talk cuz you mentioned\n",
       "20:02 that uh or we at least know that you\n",
       "20:04 work on gesture recognition right so can\n",
       "20:08 you tell us more about that and how much\n",
       "20:10 I don't know but I would be pretty\n",
       "20:12 pretty curious to know\n",
       "20:15 yeah I I think I can like give a high\n",
       "20:17 level picture it's basically about\n",
       "20:19 trying to understand uh you know if\n",
       "20:21 there's like a police officer or a\n",
       "20:24 construction worker trying to guide\n",
       "20:25 traffic like uh you know there's like a\n",
       "20:28 big event or\n",
       "20:29 so there is a police officer slow down,\n",
       "20:31 right?\n",
       "20:32 Yeah. No, like they they tell you to\n",
       "20:35 stop or they tell you to go or they tell\n",
       "20:38 you to like Yeah. So yeah, that's the\n",
       "20:41 humans like slow down when there's a\n",
       "20:42 police officer.\n",
       "20:44 That's the human brain. Uh the car tries\n",
       "20:47 to stay in the traffic rules.\n",
       "20:50 uh but uh yeah I basically try to\n",
       "20:52 understand what they want to say and\n",
       "20:54 communicate with the car and like try to\n",
       "20:57 uh you know modify its root or modify\n",
       "21:00 its behavior according to what what\n",
       "21:02 they're communicating.\n",
       "21:04 So\n",
       "21:05 I guess in your case in case of my mom\n",
       "21:07 if you say that there is a right hailing\n",
       "21:10 service the car comes without the driver\n",
       "21:13 and then all of a sudden there is an\n",
       "21:15 event like um I don't know Friday or\n",
       "21:19 whatever with a lot of people like what\n",
       "21:22 the car should do right so cuz in\n",
       "21:24 training data I guess it's less common\n",
       "21:26 to have things like that or like a\n",
       "21:29 traffic light uh breaks\n",
       "21:32 and there is a police officer are\n",
       "21:34 controlled in the traffic.\n",
       "21:36 Yeah, I think all of these cases are\n",
       "21:38 covered like Whimo has been in business\n",
       "21:40 since like I think 15 years I would say\n",
       "21:43 like they've been working on the product\n",
       "21:45 and try to cover many of the cases that\n",
       "21:49 we have. So you know the broken traffic\n",
       "21:51 light uh large crowds of people uh it's\n",
       "21:56 it's pretty pretty good around it. you\n",
       "21:58 know there are sometimes events and game\n",
       "22:00 nights and it actually does really well\n",
       "22:02 over there. So uh and also like you know\n",
       "22:05 during these cases there are these\n",
       "22:07 police officers controlling the traffic\n",
       "22:09 and like directing traffic and my job is\n",
       "22:12 to make the way more better at\n",
       "22:14 understanding\n",
       "22:17 how much can you talk about this project\n",
       "22:19 because I wonder how does it actually\n",
       "22:20 work like what kind of tech do you use\n",
       "22:24 it must be something super fast right?\n",
       "22:26 Uh\n",
       "22:27 yeah,\n",
       "22:28 so I know you you cannot go into into\n",
       "22:30 details. Uh but I guess it should be\n",
       "22:33 something super fast cuz like you need\n",
       "22:35 to make this decision in real life in\n",
       "22:37 real time, right? So something like I\n",
       "22:40 don't know yellow or something. Um yeah\n",
       "22:43 there are like a bunch of in-house\n",
       "22:44 models that use like you know uh cameras\n",
       "22:47 LA data and like all all the sensor\n",
       "22:50 information that we have or we get from\n",
       "22:52 the car and uh it's like uh way more\n",
       "22:56 does not publish its models what it\n",
       "22:59 uses. So uh these are in internal model\n",
       "23:02 that uh you know they are optimized to\n",
       "23:04 run on the car and they optimized to run\n",
       "23:07 really fast. So it's uh it's probably\n",
       "23:10 not the same neural network that was\n",
       "23:12 trained. It was like you know uh we use\n",
       "23:15 various techniques to make it much\n",
       "23:17 faster and run much faster on the car to\n",
       "23:19 like detect in very quick amounts of\n",
       "23:22 time and detect like multiple times a\n",
       "23:24 second uh about what's what's happening\n",
       "23:26 with the world. Yeah.\n",
       "23:28 How is this process called when you take\n",
       "23:30 a big model and make it smaller and\n",
       "23:33 faster?\n",
       "23:35 Um I I guess there's a bunch of ways to\n",
       "23:37 do it like you know publicly available\n",
       "23:40 ways are like something like you know\n",
       "23:41 you quantize the model.\n",
       "23:43 Yeah exactly this is this is the word I\n",
       "23:45 was looking for quantization.\n",
       "23:47 Quantization. Yes. So you make it like\n",
       "23:50 you make it smaller you make it faster\n",
       "23:52 with with quantization. So many of\n",
       "23:55 similar techniques but uh there are a\n",
       "23:57 whole bunch of other stuff that we also\n",
       "23:59 do uh internally.\n",
       "24:03 Yeah, I I guess like I I think that's\n",
       "24:05 the extent of it.\n",
       "24:09 I was just thinking not to torture you\n",
       "24:11 and put you in a uncomfortable position\n",
       "24:14 by asking more and I was thinking what\n",
       "24:16 should I ask next cuz you also did a few\n",
       "24:18 other interesting things and one of them\n",
       "24:22 which I find quite interesting is uh\n",
       "24:26 this malaria mapping project in Africa.\n",
       "24:29 Um can you tell us more about these\n",
       "24:31 projects?\n",
       "24:33 Yeah, I think this was when I was in\n",
       "24:35 Morgan Stanley and I was like oh this\n",
       "24:37 domain is really interesting and I want\n",
       "24:39 to do more projects about this. Uh so I\n",
       "24:42 I joined this organization called OMina\n",
       "24:44 and basically they work they have like\n",
       "24:46 AI for good projects where you have a\n",
       "24:50 like a nonprofit company that comes in\n",
       "24:52 with their uh problem and you have these\n",
       "24:55 volunteer ML engineers. Some of them are\n",
       "24:58 trying to learn, some of them are\n",
       "25:00 experts and they want to contribute to\n",
       "25:01 the community and they put you in like\n",
       "25:03 groups of 30 40 people who work together\n",
       "25:06 on this problem. So uh there was this\n",
       "25:10 nonprofit organization called Zap\n",
       "25:12 Malaria. They were trying to like uh\n",
       "25:14 lead efforts for fumigation in Africa.\n",
       "25:18 So you know they the the first iteration\n",
       "25:21 was to just like go in places and\n",
       "25:23 fumigate places uh where there could be\n",
       "25:26 high possibility of malaria mosquitoes\n",
       "25:28 so that to prevent like you know the the\n",
       "25:30 breeding of mosquitoes and the spread of\n",
       "25:32 malaria in those region. What they\n",
       "25:34 wanted us to do was to like determine\n",
       "25:36 you know make this process more\n",
       "25:38 efficient like uh they don't want to go\n",
       "25:40 to every region or every city in a given\n",
       "25:43 region and fumigate. they only want to\n",
       "25:45 target places where there's a high\n",
       "25:47 probability of mosquitoes. So they\n",
       "25:49 wanted to use machine learning models or\n",
       "25:51 AI to do that. So what what what we\n",
       "25:55 thought that okay if we have like\n",
       "25:56 satellite images or we have some\n",
       "25:58 knowledge of where could be like you\n",
       "26:00 know marshy lands or uh where areas\n",
       "26:03 where like you know water stagnates\n",
       "26:05 which is typically where mosquitoes have\n",
       "26:07 breeding grounds. we could just like\n",
       "26:09 identify these areas and these people\n",
       "26:12 could just go with their fumigation and\n",
       "26:14 just fumigate those areas and that would\n",
       "26:16 be much more efficient. It would save\n",
       "26:18 like so many manpower, so much cost and\n",
       "26:20 you know for these kind of nonprofits\n",
       "26:22 cost is a very big I guess\n",
       "26:24 consideration. So I guess with this team\n",
       "26:28 we worked in multiple groups. One team\n",
       "26:31 tried to use satellite images to detect\n",
       "26:33 like water bodies, stagnant water\n",
       "26:34 bodies. What my model did was it used\n",
       "26:37 topographic information. So we have this\n",
       "26:40 Google data gives you uh information\n",
       "26:42 about the geography of a particular\n",
       "26:44 region and then you try to basically\n",
       "26:47 train a model to identify what could be\n",
       "26:49 like low-lying areas where there's a\n",
       "26:51 high possibility of water stagnating and\n",
       "26:53 detect those areas and like you know let\n",
       "26:55 them know. So uh I think uh at the end\n",
       "26:59 like we used kind of an ensemble system\n",
       "27:01 that could use satellite images,\n",
       "27:02 topographic information and give you\n",
       "27:04 this data which they later made some\n",
       "27:06 changes and integrated into their whole\n",
       "27:08 model and I think their website also has\n",
       "27:11 some good very good results that they\n",
       "27:13 achieved with our models uh with this\n",
       "27:15 but yeah it was like a completely\n",
       "27:17 volunteerbased AI for good project.\n",
       "27:20 So you worked at Morgan Stanley and\n",
       "27:22 managed to also contribute to AI for\n",
       "27:26 social good project because I I don't\n",
       "27:28 know about Morgan Stanley but usually\n",
       "27:30 these financial institutions\n",
       "27:33 are not known for um\n",
       "27:36 um you know good work life balance.\n",
       "27:40 Yeah, I I think like it's um I was there\n",
       "27:44 for 2 years so I was already pretty\n",
       "27:47 efficient with all the systems and I\n",
       "27:49 knew where everything was. So I uh I was\n",
       "27:54 and I was interested in learning more\n",
       "27:55 because in financial institutions\n",
       "27:57 generally like you know these newer\n",
       "27:59 technologies like ML and all it's not\n",
       "28:02 easily adoptable. So it's it's really\n",
       "28:04 hard to get started a project. So I I I\n",
       "28:08 worked basically on weekends for this\n",
       "28:09 project that I had.\n",
       "28:11 Yeah, makes sense. Yeah, like I have\n",
       "28:14 PTSD now like when you talk about\n",
       "28:16 because I worked at a bank too. It was\n",
       "28:18 2012 so it was a while ago and it was so\n",
       "28:21 difficult to get even like a new\n",
       "28:23 database like to use.\n",
       "28:26 Mhm.\n",
       "28:26 Uh like let alone starting a new project\n",
       "28:29 that involves machine learning. No,\n",
       "28:31 forget about that.\n",
       "28:33 uh and we deploy it even uh once per\n",
       "28:36 month and if we didn't have a chance to\n",
       "28:39 prepare some things for the deployment\n",
       "28:43 uh cuz there is a process like you need\n",
       "28:44 to do some sort of audit I don't know I\n",
       "28:47 don't remember\n",
       "28:48 and if you miss this line then you wait\n",
       "28:51 for one month for the next cycle right\n",
       "28:53 and then only then you can see your work\n",
       "28:56 um actually being applied to real data\n",
       "29:00 and that was frustrating right Uh so\n",
       "29:03 well well I guess there are reasons why\n",
       "29:04 there is there are these bureaucratic\n",
       "29:06 processes right cuz like it's money.\n",
       "29:09 Yeah, I I think I 100% like agree and\n",
       "29:12 you know I can resonate with what you're\n",
       "29:14 saying. You know there are these like\n",
       "29:16 big processes that happen before every\n",
       "29:18 release and deployment that you must do\n",
       "29:20 every single time and it after a point\n",
       "29:23 it gets repetitive and it's like even\n",
       "29:25 for like putting the smallest thing in\n",
       "29:28 production you need to go through this\n",
       "29:29 and at some point it gets to you and\n",
       "29:32 you're like I I want to like do\n",
       "29:34 innovation. I want to like make impact.\n",
       "29:36 I don't want to do like get caught in\n",
       "29:38 processes and stuff.\n",
       "29:40 So yeah,\n",
       "29:41 which makes me wonder now how does it\n",
       "29:43 work with self-driving cars cuz it's\n",
       "29:45 also not a thing you can easily roll\n",
       "29:47 out, right? So first of all, there is\n",
       "29:49 this component that um like you cannot\n",
       "29:53 really afford having bucks there, right?\n",
       "29:55 cuz like if there is a buck and then a\n",
       "29:58 car misbehaves and I don't know hits\n",
       "30:00 traffic light uh and then like\n",
       "30:04 it's good if nobody gets injured but\n",
       "30:06 like what if somebody gets injured and\n",
       "30:08 it's super bad right? uh especially with\n",
       "30:12 um competitiveness like there are so\n",
       "30:14 many there are multiple\n",
       "30:17 um cars who like how to say companies\n",
       "30:20 that work on self-driving of course you\n",
       "30:23 want to be the best one right so I guess\n",
       "30:26 you have to be super careful when you\n",
       "30:28 work on things like that so how do you\n",
       "30:30 go about deployment in this case\n",
       "30:33 yeah I I think like there is again a lot\n",
       "30:37 a I would say multi-month process of you\n",
       "30:40 know deploying any I guess news release\n",
       "30:43 or software because like you mentioned\n",
       "30:46 it's a very sensitive and safety\n",
       "30:48 critical domain. So we want to be\n",
       "30:50 absolutely sure that it doesn't like\n",
       "30:52 negatively impact and doesn't have any\n",
       "30:54 bad behavior out in the open or out in\n",
       "30:57 the wild uh in the world. Mhm.\n",
       "30:58 So uh yes uh I think there are different\n",
       "31:01 components you know every time you push\n",
       "31:03 a change you do these whole bunch of\n",
       "31:05 evals you uh try to rerun uh from\n",
       "31:09 existing logs you rerun a lot of\n",
       "31:12 different evaluations and then you\n",
       "31:15 combine your changes with all other\n",
       "31:16 changes and then again there like for\n",
       "31:18 many months you have drivers driving in\n",
       "31:22 multiple areas testing out the software\n",
       "31:24 and like after you have accumulated\n",
       "31:27 enough data points joints that okay this\n",
       "31:29 is safe and this is good to go only then\n",
       "31:32 you deploy it. Uh but yeah the joint\n",
       "31:34 evals and you know uh the drivers\n",
       "31:37 actually driving around like we\n",
       "31:38 engineers are not involved so much with\n",
       "31:40 that. So that process has like it has a\n",
       "31:44 very different team and that is very\n",
       "31:45 well managed and they go through it.\n",
       "31:48 But even as engineers we\n",
       "31:50 Yeah. Yeah. There are there's tons of I\n",
       "31:52 would say there's lot more than\n",
       "31:53 financial company because\n",
       "31:55 you know in like in Morgan Stanley I've\n",
       "31:58 seen there's been losses there's been\n",
       "32:00 millions of dollars of losses but that\n",
       "32:01 you can recover but you know this this\n",
       "32:03 is like someone's life or someone's\n",
       "32:05 safety and it's much more important.\n",
       "32:09 Yeah that's interesting. Um, which\n",
       "32:12 reminds me of this uh case. Remember a\n",
       "32:14 few years back um there was a bug in\n",
       "32:17 Windows computers and all the airports\n",
       "32:19 had blue screen of death. Uh what was\n",
       "32:22 that? Crowd Strike, right? It was crowd\n",
       "32:24 strike.\n",
       "32:24 Yeah, Crowd Strike I think. Yes, Crowd\n",
       "32:27 Strike.\n",
       "32:27 Nobody knew about this thing that this\n",
       "32:29 thing existed until like I had no idea\n",
       "32:33 this company ever existed. uh they got\n",
       "32:37 provider\n",
       "32:38 lot of they got a lot of publicity out\n",
       "32:40 of that negative one but uh now we know\n",
       "32:44 what it is.\n",
       "32:45 Yeah. And uh so the story there was that\n",
       "32:48 they wrote uh something out and then it\n",
       "32:50 broke right.\n",
       "32:52 Yes. Yeah. I think the test thing they\n",
       "32:55 they missed some test cases and\n",
       "32:56 something very unexpected happened over\n",
       "32:59 there.\n",
       "32:59 Yeah. I don't know what happened though\n",
       "33:01 but it was a talk of the town I would\n",
       "33:03 say. Mhm. Yeah. But I guess what you\n",
       "33:06 work with is kind of similar in a sense\n",
       "33:09 that there is also the hardware\n",
       "33:11 component, right? So in Morgan Stanley,\n",
       "33:14 I don't know about you, but I assume it\n",
       "33:16 was probably just software, right? You\n",
       "33:17 didn't need to,\n",
       "33:18 of course, like you run on a computer.\n",
       "33:21 Uh but chances are that um you know, you\n",
       "33:25 don't run native C code. Most likely\n",
       "33:26 it's Java or Python or I don't know\n",
       "33:29 something like that.\n",
       "33:30 Yes. Yes.\n",
       "33:30 Um but like once you need to use uh\n",
       "33:34 something low level, something native\n",
       "33:36 and you need to be closer to hardware\n",
       "33:39 uh then things can get complicated,\n",
       "33:42 right? And uh in case of self-driving,\n",
       "33:44 you're very very closely connected with\n",
       "33:46 hardware cuz you actually need to I\n",
       "33:48 don't know steer the wheel or\n",
       "33:50 hit the brakes or whatever.\n",
       "33:53 Yeah, I guess uh definitely connected to\n",
       "33:56 hardware but for my role specifically I\n",
       "33:59 mostly work on the software that drives\n",
       "34:01 it and then there are different teams\n",
       "34:03 that work on the hardware aspect like\n",
       "34:06 you know or connection between the\n",
       "34:07 hardware and software where you do this\n",
       "34:09 whole like making the model faster and\n",
       "34:12 stuff\n",
       "34:13 but uh yes it like every time you push\n",
       "34:15 any new change there's this whole suite\n",
       "34:18 that needs to run and it's it's it's a\n",
       "34:20 very comprehensive very thorough ES Yes.\n",
       "34:22 Yes.\n",
       "34:24 Are you working on any um um side\n",
       "34:27 projects right now?\n",
       "34:29 Uh not right now. Uh what I'm doing\n",
       "34:32 right now is the AI guide dog thing that\n",
       "34:35 I was doing. I'm I'm still mentoring a\n",
       "34:37 group uh on that project but not like\n",
       "34:41 it's just like in a mentor capacity. Not\n",
       "34:43 like working on anything right now. I\n",
       "34:46 guess right now the work work aspect is\n",
       "34:48 a bit busy at this time of the year. you\n",
       "34:51 know it's before the November like when\n",
       "34:54 everything slows down uh we have a lot\n",
       "34:56 of work in September October months\n",
       "34:59 and then in December it's chill\n",
       "35:01 yes a bit chill during the holidays here\n",
       "35:05 okay\n",
       "35:06 I guess it's the same for most companies\n",
       "35:08 I think I had similar experiences in\n",
       "35:12 in Europe definitely\n",
       "35:14 yeah yeah\n",
       "35:15 I don't know about states but\n",
       "35:18 yeah I I think side projects are in like\n",
       "35:21 I I some sometimes start something in\n",
       "35:23 December and then it's it's good if I'm\n",
       "35:25 able to complete it otherwise I wait for\n",
       "35:28 the next December to take it off.\n",
       "35:30 But uh yes yeah I think mentoring is\n",
       "35:33 easier because you have uh people\n",
       "35:36 actually working on something and who\n",
       "35:38 have more time to work on it and you can\n",
       "35:39 help them in their process.\n",
       "35:41 Yeah. Yeah.\n",
       "35:42 Uh what I like about mentoring is you\n",
       "35:45 can test ideas without actually spending\n",
       "35:48 a lot of time implementing them.\n",
       "35:50 But you know the outcome, you learn the\n",
       "35:52 outcome from the person you mentor. So\n",
       "35:54 you can just say, \"Hey, you can try this\n",
       "35:56 and that.\" And then a few days later\n",
       "35:58 they come and say if it worked or not,\n",
       "36:00 right? And then you kind of you still\n",
       "36:02 learn from this experience too. Like you\n",
       "36:04 not only teach, you also learn. Um and\n",
       "36:07 then you can know okay\n",
       "36:09 this thing for this case uh maybe not is\n",
       "36:12 the best one so we can try something\n",
       "36:15 else then you also um get experience by\n",
       "36:19 mentoring\n",
       "36:20 for sure I I think that's how uh it's\n",
       "36:23 been working and even like you have if\n",
       "36:24 you have like a bigger team you can try\n",
       "36:26 out multiple ideas at a time and uh the\n",
       "36:29 people actually working on it they they\n",
       "36:31 joined that project because they like it\n",
       "36:33 and they are like super invested in it\n",
       "36:36 So it's nice to work along they're super\n",
       "36:38 passionate about it. So it's you trying\n",
       "36:41 out different ideas without actually you\n",
       "36:43 know spending a lot of time but you you\n",
       "36:46 also get to mentor people. So yeah, it's\n",
       "36:48 it's a mix of good both good good\n",
       "36:51 things. Yeah.\n",
       "36:53 Uh with all these new things coming up\n",
       "36:55 coming out um of AI LLM and whatnot. Um\n",
       "37:00 so since you were working in computer\n",
       "37:02 vision but all these new things they are\n",
       "37:04 mostly related to NLPs and text NLP and\n",
       "37:08 texts. Um, do you also find time to try\n",
       "37:11 to stay up to date with this field or\n",
       "37:15 you you're focusing more on what you do\n",
       "37:18 at work?\n",
       "37:20 Actually, I in CMU I was in the language\n",
       "37:23 technologies institute. So, I actually\n",
       "37:25 studied NLP and then transitioned to CV\n",
       "37:29 just before the whole Chad GPT boom.\n",
       "37:32 Yeah, I I I graduated in December 2022\n",
       "37:36 and then like I guess Chad GPT was\n",
       "37:38 around the same time and like few months\n",
       "37:40 later it was like super big and then the\n",
       "37:42 whole AI bubble with the LLM's like\n",
       "37:45 booming off. Uh but uh yes I do\n",
       "37:49 definitely stay ab breast with\n",
       "37:51 everything like even when I was\n",
       "37:53 switching my roles like from Tesla to I\n",
       "37:56 did a lot of different interviews and\n",
       "37:59 the way it works in the industry is like\n",
       "38:02 although you are from a CV background\n",
       "38:04 it's the same underlying fundamentals.\n",
       "38:06 So you know you still are eligible to\n",
       "38:09 interview for many of the LLM roles and\n",
       "38:11 I did interview with like a bunch of\n",
       "38:13 places where it was only NLP focused uh\n",
       "38:16 not much uh um CV but many times it's\n",
       "38:20 also a hybrid like multimodel uh large\n",
       "38:23 language models are very popular now and\n",
       "38:26 um many teams who I I I guess like they\n",
       "38:30 need CV expertise along with their LL\n",
       "38:33 inhouse like NLP folks so uh definitely\n",
       "38:36 like you know I read a lot of papers um\n",
       "38:40 that deal with this kind of multimodel\n",
       "38:42 LLM stuff or read a lot of blogs or uh\n",
       "38:46 even like you know the LLM techniques\n",
       "38:48 that they use it's it's good to have\n",
       "38:50 that knowledge because many of these\n",
       "38:52 techniques are general deep learning\n",
       "38:54 techniques rather than just that are\n",
       "38:56 applicable to LLMs. So you can use some\n",
       "39:00 of these techniques even for your models\n",
       "39:02 that work with CV data. So yeah at the\n",
       "39:05 end of the day it's all deep learning uh\n",
       "39:07 and it's is as much interesting to know\n",
       "39:11 about it and like it's as much\n",
       "39:12 useful.\n",
       "39:13 [Music]\n",
       "39:14 So I my masters was um in 20134\n",
       "39:21 uh it wasn't focusing on um even not on\n",
       "39:24 machine learning but I was taking a lot\n",
       "39:26 of extra courses uh in particular I was\n",
       "39:29 quite interested in LP at NLP but um NLP\n",
       "39:33 was quite different so it was\n",
       "39:35 pre-transformer era\n",
       "39:37 yes\n",
       "39:38 um so we were doing like um logistic\n",
       "39:41 regression this kind of stuff right to I\n",
       "39:43 don't know.\n",
       "39:45 Yeah. So like we if you want to identify\n",
       "39:48 part of speech\n",
       "39:50 and then there was I I don't even\n",
       "39:52 remember how these models were called.\n",
       "39:54 Uh but today you just throw everything\n",
       "39:56 at LM and it tells you okay here's a\n",
       "39:58 noun or there's names there are named\n",
       "40:01 entities. uh back then uh like you had\n",
       "40:04 to train models for that and then you\n",
       "40:07 had to have a corpus uh and then this uh\n",
       "40:10 has to be had to be labeled and then you\n",
       "40:13 say for this corpus like these are my\n",
       "40:15 named entities like and then you train a\n",
       "40:17 model. So these things are way easier\n",
       "40:20 today.\n",
       "40:21 Mhm.\n",
       "40:21 I wonder in your case when you studied\n",
       "40:23 NLP you already covered deep learning\n",
       "40:26 right? So for you when these LLMs came\n",
       "40:29 up like when they started to be big and\n",
       "40:32 charge BT like people started using it\n",
       "40:35 for you cuz you studied deep learning\n",
       "40:37 techniques right so for you it wasn't\n",
       "40:39 such a big leap right\n",
       "40:42 yeah I think uh I still remember like\n",
       "40:44 when I was in undergrad I did take a few\n",
       "40:47 ML courses and that time it was these\n",
       "40:49 very basic uh natural language\n",
       "40:52 processing techniques like part of\n",
       "40:53 speech and uh Identity correlation and\n",
       "40:56 bag of words and logistic regression\n",
       "40:58 like started off with that but then like\n",
       "41:01 during that time deep learning was also\n",
       "41:03 very popular. So uh in my masters there\n",
       "41:06 was a lot of focus on deep learning\n",
       "41:07 transformer based systems because that\n",
       "41:09 was already big at that point. But uh\n",
       "41:12 now like if you think about it, it's all\n",
       "41:14 based on the same fundamentals like you\n",
       "41:16 know your LLMs they're based on\n",
       "41:18 transformers which is based on like the\n",
       "41:20 attention mechanism and uh that boils\n",
       "41:23 down to your representation learning\n",
       "41:25 where you have like embeddings and the\n",
       "41:27 embeddings have similarity and like the\n",
       "41:30 whole core of LLM could be like you know\n",
       "41:33 said it's like anation learning kind of\n",
       "41:36 thing\n",
       "41:36 which uh which is like where the basics\n",
       "41:39 began which is where the fundament\n",
       "41:41 began. So for sure like I did do a lot\n",
       "41:44 of deep learning and that was really\n",
       "41:46 helpful when jumping to LLMs but uh I\n",
       "41:49 feel like uh with LLMs there's a lot of\n",
       "41:53 more creative or ingenuity in how the\n",
       "41:58 pre-training how they made it work or\n",
       "42:00 the RL stuff like I I am I have never\n",
       "42:04 taken an RL uh reinforcement learning\n",
       "42:06 course. I don't know what it is but uh I\n",
       "42:09 did read the papers and I it was hard to\n",
       "42:12 understand in the beginning but like uh\n",
       "42:16 if you tie it down to okay some basic\n",
       "42:18 principles and there's like so many good\n",
       "42:20 blogs explaining things uh about it it\n",
       "42:24 does take some effort uh but like you\n",
       "42:27 can just like try to piece together\n",
       "42:29 things uh\n",
       "42:31 but it does take some effort uh of\n",
       "42:33 course like if I had not learned about\n",
       "42:35 deep learning if I had not learned about\n",
       "42:37 this representation learning or\n",
       "42:38 embeddings, it would have been much more\n",
       "42:40 harder for me.\n",
       "42:43 Yeah, I I remember like I mentioned in\n",
       "42:45 Morgan Stand doing these basic things\n",
       "42:47 with the recommendation systems and like\n",
       "42:49 graph neural networks. It took me like\n",
       "42:51 almost two weeks to go through one paper\n",
       "42:53 and it was just like eight pages and at\n",
       "42:56 that time I did not have any background\n",
       "42:58 about deep learning. So I think having\n",
       "42:59 that background definitely makes it much\n",
       "43:02 easier to grasp these concepts.\n",
       "43:04 Mhm. So now when you read papers for\n",
       "43:06 you, it doesn't take two weeks usually.\n",
       "43:10 No, no, it it's like probably an hour at\n",
       "43:12 max.\n",
       "43:14 So it's it's much more efficient now.\n",
       "43:16 For me, I think it would be like two\n",
       "43:18 weeks. If I needed to get into any\n",
       "43:21 modern uh papers like this uh I don't\n",
       "43:25 know if I go to archive and take any\n",
       "43:27 paper uh about an OP or computer vision.\n",
       "43:31 Yeah. Well, good that we have chat GPT\n",
       "43:33 so I can ask it to explain things.\n",
       "43:36 That is so good now. Like it was not\n",
       "43:38 there back when we were in school and\n",
       "43:40 college\n",
       "43:41 doing assignments. Where was strategy\n",
       "43:44 then? Interesting that you mentioned you\n",
       "43:48 didn't have any prior experience with\n",
       "43:49 reinforcement learning cuz I thought\n",
       "43:51 reinfor reinforcement learning is\n",
       "43:53 something that used quite often for um\n",
       "43:58 um driving too cuz for me uh before this\n",
       "44:02 whole um LLM space appeared. So for me\n",
       "44:06 AI was um so there was machine learning\n",
       "44:10 which was kind of part of AI but for me\n",
       "44:12 machine learning was machine learning\n",
       "44:13 never like AI uh but this reinforcement\n",
       "44:17 learning you can actually get an agent\n",
       "44:20 to do things in the environment\n",
       "44:23 and work there were companies I\n",
       "44:25 interviewed with one of them who were\n",
       "44:27 creating these environments for\n",
       "44:29 self-driving cars to be like a test bed\n",
       "44:31 or whatever like for testing uh so they\n",
       "44:35 have the environment with streets and\n",
       "44:36 what not. So they look very realistic\n",
       "44:39 and I don't know um it was in Germany so\n",
       "44:43 I guess like BMWs and Audi's and whatn\n",
       "44:46 not who like companies who also work at\n",
       "44:49 on self-driving here in Germany they\n",
       "44:51 could use this uh environment to test\n",
       "44:54 their cars right and the idea there was\n",
       "44:56 that they have this reinforcement\n",
       "44:59 learning framework where they can the\n",
       "45:02 car can just go wild and learn from like\n",
       "45:04 okay like if I uh hit a pedestrian and\n",
       "45:07 then there is a huge penalty and then it\n",
       "45:09 learns not to do this, right? Um, so for\n",
       "45:12 me it was interesting. It didn't work\n",
       "45:13 out so I didn't join the company and it\n",
       "45:16 was funny. It was like a company with\n",
       "45:19 four people in a basement and a lot of\n",
       "45:21 GPUs.\n",
       "45:22 Uh, so they needed a one and they\n",
       "45:24 thought, uh, yeah, I have a kit and\n",
       "45:26 doesn't sound very stable.\n",
       "45:30 Wow. Okay. Okay.\n",
       "45:32 Yeah. But it was a good thing.\n",
       "45:34 Yeah. Reinforcement learning is kind of\n",
       "45:37 interesting. I think I I my first\n",
       "45:39 interaction with reinforcement learning\n",
       "45:41 was like with all these robots like we\n",
       "45:43 had these robo wars in college where you\n",
       "45:45 build your robot and like you go to a\n",
       "45:47 tech festival and you like compete\n",
       "45:49 against each other\n",
       "45:51 and I I I think uh reinforcement\n",
       "45:53 learning is still a big part of\n",
       "45:55 robotics. Um for me personally like so\n",
       "45:59 far in my career I've like whatever\n",
       "46:01 career has been in computer vision or\n",
       "46:03 robotics so to speak it has mostly been\n",
       "46:05 on the computer vision side so\n",
       "46:07 perception side trying to understand the\n",
       "46:09 world and then I I believe like\n",
       "46:11 reinforcement learning comes into\n",
       "46:13 picture when you're trying to modify the\n",
       "46:14 behavior of the agent or trying to teach\n",
       "46:16 it how to uh like behave in the world it\n",
       "46:20 is in. Um so these are like two separate\n",
       "46:23 parts of the stack is one is you try to\n",
       "46:25 understand or make the agent understand\n",
       "46:27 the world which is where I work and then\n",
       "46:30 trying to make it behave a certain way\n",
       "46:31 which is I I I believe like\n",
       "46:33 reinforcement learning could be used. So\n",
       "46:35 yeah I never had to like even though I'm\n",
       "46:38 in the self-driving industry I never had\n",
       "46:39 to like work on the other part of the\n",
       "46:42 stack. I don't think I'll be very good\n",
       "46:43 at it. I've like I skipped all\n",
       "46:46 reinforcement learning courses in\n",
       "46:47 college because I just found it too\n",
       "46:50 hard. So yeah.\n",
       "46:52 Yeah. But I imagine also it's not uh you\n",
       "46:54 will not let a car go wild and learn uh\n",
       "46:58 the way to interact with pedestrians\n",
       "47:01 right outside\n",
       "47:03 uh to actually do reinforcement learning\n",
       "47:07 fun.\n",
       "47:07 Yeah. Yeah. That's for sure. Uh\n",
       "47:09 it's karmagon. Honest honestly, I don't\n",
       "47:12 know if we use reinforcement learning.\n",
       "47:14 I've never tried to find out\n",
       "47:16 because it looks like more like a fun uh\n",
       "47:19 project to do like when you have a\n",
       "47:22 emulator, right?\n",
       "47:24 Yeah.\n",
       "47:24 Uh but like in real life probably you\n",
       "47:27 still have there's actually a question\n",
       "47:28 from Ole. Ole is asking uh I think the\n",
       "47:32 question is about self-driving.\n",
       "47:34 The question is is this full AI or mix\n",
       "47:36 of rules and AI? So I am assuming Le is\n",
       "47:39 referring to uh to self-driving cuz I\n",
       "47:44 guess like full AI would be this\n",
       "47:45 reinforcement learning right when the\n",
       "47:47 car just learns to drive by itself. Uh\n",
       "47:50 but we still need to add some rules,\n",
       "47:52 right? Like what's um what's the current\n",
       "47:55 state of the art in AI or in\n",
       "47:56 self-driving?\n",
       "47:59 Um yeah, I think like all environments\n",
       "48:01 like even in reinforcement learning or\n",
       "48:04 uh uh other ways to teach the car there\n",
       "48:07 would be some constraints that you\n",
       "48:09 impose upon it like you know the the\n",
       "48:12 rules of the world like you shouldn't\n",
       "48:13 like go against the traffic there are\n",
       "48:17 the these you need to put these\n",
       "48:19 constraints u so it's like I I I don't\n",
       "48:24 think it's full do whatever learn\n",
       "48:28 however you want to drive.\n",
       "48:30 Uh definitely constrained by a lot of\n",
       "48:32 rules and also I I would say like as you\n",
       "48:35 try to expand into different countries\n",
       "48:37 or different continents there are a\n",
       "48:39 whole bunch of new rules that go about\n",
       "48:41 over there.\n",
       "48:42 Uh sometimes you like even in the same\n",
       "48:46 country even different cities have\n",
       "48:48 different patterns of driving. Sometimes\n",
       "48:50 the travels are very aggressive.\n",
       "48:51 Sometimes it's like more rule following,\n",
       "48:53 right?\n",
       "48:54 So it needs to be adaptable that way and\n",
       "48:56 constrained in specifically.\n",
       "48:59 Yeah. So in Italy and in Germany, it's\n",
       "49:02 so so different like the way people\n",
       "49:05 drive. So in Germany, at least in\n",
       "49:06 Berlin, people are driving slow and it's\n",
       "49:09 very easy to cross the street. But in\n",
       "49:11 Italy, especially in the south, good\n",
       "49:12 luck. like you have to be you just have\n",
       "49:14 to go across the street then they will\n",
       "49:17 stop otherwise they will just keep\n",
       "49:18 driving right\n",
       "49:20 okay\n",
       "49:21 yeah yeah I I think like uh it still\n",
       "49:24 needs to learn all these patterns\n",
       "49:26 in the world so a lot of constraints\n",
       "49:28 over that's why it's such a hard problem\n",
       "49:30 like you know it changes so so so much\n",
       "49:34 with geographies\n",
       "49:35 yeah I was thinking about chess because\n",
       "49:37 in chess and in also in go um they used\n",
       "49:40 eventually reinforcement learning to\n",
       "49:42 build this uh state-of-the-art uh models\n",
       "49:45 for playing these games. Um but what\n",
       "49:47 they did is they let um the I don't know\n",
       "49:51 how to say agent or whatever the players\n",
       "49:53 um the AI go wild and do whatever they\n",
       "49:56 want. So instead of learning from\n",
       "49:59 previous games, they just let the game\n",
       "50:01 the AI explore the game and then\n",
       "50:05 eventually because they were not bound\n",
       "50:07 by the training data by the what people\n",
       "50:10 played in the past, they could play\n",
       "50:12 better than humans, right? Um but I\n",
       "50:15 guess with AI, with self-driving, it's\n",
       "50:18 kind of different, right? So you still\n",
       "50:20 need to obey. But yeah, in chess you\n",
       "50:23 have rules. the knight jumps like uh\n",
       "50:26 this right or the bishop goes by on\n",
       "50:29 diagonals right so you have these rules\n",
       "50:31 in chess too\n",
       "50:32 yeah I I think like the problem here or\n",
       "50:35 or the difference here what I see is\n",
       "50:36 with chess the rules are fixed like you\n",
       "50:39 know\n",
       "50:39 yeah very\n",
       "50:40 every piece has a given purpose and\n",
       "50:43 there's no rules beyond that like you\n",
       "50:45 have these pieces and 16 pieces and then\n",
       "50:49 you have the 16 set of rules that's it\n",
       "50:52 and then you can do whatever and then\n",
       "50:54 you can explore and then AI just has\n",
       "50:57 like full reign to do whatever uh it\n",
       "51:00 wants to do. But in self-driving the\n",
       "51:02 rules are also constantly evolving like\n",
       "51:05 you have like infinite number of rules I\n",
       "51:08 would say. So it's it's hard to like\n",
       "51:13 teach the model in such a changing\n",
       "51:15 environment uh so to speak. But uh yeah\n",
       "51:19 uh yeah I honestly don't know if we use\n",
       "51:22 reinforcement learning but yeah\n",
       "51:24 definitely the constraints do come into\n",
       "51:26 picture whatever model we use. Yeah, I\n",
       "51:28 see that there's a question from Adonis.\n",
       "51:30 He just asked it. How is uh how does the\n",
       "51:33 testing process go for sensitive cases\n",
       "51:35 like autonomous driving? Two developers\n",
       "51:38 inherit some general tests and they have\n",
       "51:41 to pass uh are there any stages? That's\n",
       "51:44 a very large a big loaded question. But\n",
       "51:48 uh I guess yeah the question is like uh\n",
       "51:50 how does testing uh how is testing\n",
       "51:53 organized for self-driving cars?\n",
       "51:56 Yeah, I I guess like uh it it depends on\n",
       "51:59 like what what change you're trying to\n",
       "52:00 do. So I work on pedestrians and\n",
       "52:03 gestures. So we have a bunch of like\n",
       "52:06 evaluations around cases where you have\n",
       "52:09 these pedestrians and or cases which\n",
       "52:11 have happened in the past and you try to\n",
       "52:14 like rerun your new model on those cases\n",
       "52:16 and then that is the first stage and\n",
       "52:18 then the next stage you uh evaluate\n",
       "52:20 overall with various different scenarios\n",
       "52:22 from the world where other pedestrians\n",
       "52:24 are involved and uh like the like the\n",
       "52:28 question mentioned there are different\n",
       "52:29 stages like you starts off small and\n",
       "52:31 then you slowly get like bigger and more\n",
       "52:34 comprehensive eval sets and then you\n",
       "52:37 roll it out slowly like you let drivers\n",
       "52:40 take it to the world and drive few miles\n",
       "52:42 around then you deploy it to the larger\n",
       "52:44 field. So it happens the rollout happens\n",
       "52:47 in stages uh that way.\n",
       "52:49 Mhm.\n",
       "52:51 And um\n",
       "52:53 another question about LLMs. We already\n",
       "52:56 talked LLMs can do computer vision too,\n",
       "52:59 right? Uh but they are\n",
       "53:03 kind of slow, right? Is there do you\n",
       "53:06 think um we can apply this with for\n",
       "53:11 self-driving at some point? Like does it\n",
       "53:13 actually make sense to use generative\n",
       "53:15 models for that?\n",
       "53:17 Yeah, I I think like there uh there have\n",
       "53:20 been a lot of attempts. So if you see\n",
       "53:22 the latest state-of-the-art even in\n",
       "53:24 literature or even some companies such\n",
       "53:26 as wave, they are trying to in fact use\n",
       "53:29 like multimodel LLMs for a self like end\n",
       "53:32 to end driving self-driving case. So\n",
       "53:36 there is definitely a lot of room mainly\n",
       "53:38 because LLMs are trained or pre-trained\n",
       "53:40 on so much amount of data. they have so\n",
       "53:43 much of world knowledge that's e easy to\n",
       "53:46 teach them more or like you know have\n",
       "53:48 them behave certain ways because they\n",
       "53:50 already have a lot of knowledge. Uh the\n",
       "53:52 challenge still remains in you know how\n",
       "53:54 do you make them fast enough. So the you\n",
       "53:57 have to like probably do a lot of\n",
       "53:59 tradeoffs. There needs to be a lot of\n",
       "54:01 different techniques but definitely it's\n",
       "54:04 something that's been explored very\n",
       "54:06 actively in current research as well as\n",
       "54:08 by some companies. And there are in fact\n",
       "54:11 systems out there that use LLMs for the\n",
       "54:14 self-driving use case\n",
       "54:16 because I guess uh we talked about\n",
       "54:17 different patterns in different\n",
       "54:19 countries like Italy versus Germany.\n",
       "54:22 LLM might know might not might know\n",
       "54:25 about these things, right? It might know\n",
       "54:26 that uh I don't know if you go to south\n",
       "54:31 it's more chaotic. If you go to north\n",
       "54:32 it's more strict, right? So something\n",
       "54:34 like this. Uh so maybe for it it's\n",
       "54:36 easier to actually use it for I don't\n",
       "54:41 know I'm just making this up I guess but\n",
       "54:43 uh maybe it already knows because it uh\n",
       "54:45 the ways are trained they trained from\n",
       "54:48 internet forums where Germans can go to\n",
       "54:52 forums and complain about drivers in\n",
       "54:53 Italy right\n",
       "54:55 yeah I guess that's the hope that it has\n",
       "54:58 some semblance of knowledge about like a\n",
       "55:01 lot of different things that probably\n",
       "55:04 you're well curated ated data set might\n",
       "55:06 not have like when you try to train a\n",
       "55:08 model you curate a data set and you only\n",
       "55:10 put in cases that you might be aware of\n",
       "55:14 but with LLMs the thing is that it has\n",
       "55:16 so much of world knowledge that you\n",
       "55:19 there are high possibility that it might\n",
       "55:21 know these things and it it might help\n",
       "55:22 you in your tuning process to get it\n",
       "55:25 across the world.\n",
       "55:28 Okay, maybe last question and we wrap it\n",
       "55:30 up. So if I want to work on self-driving\n",
       "55:33 cars, uh um\n",
       "55:36 what should I do? What should I study?\n",
       "55:38 Uh how do you uh can I get into this\n",
       "55:40 industry?\n",
       "55:42 Yeah, I I guess like uh it again starts\n",
       "55:45 with uh\n",
       "55:47 deep learning. So the way I did it was I\n",
       "55:50 was good at deep learning. I got got\n",
       "55:52 into the AI guard dog project which was\n",
       "55:54 a similar use case like you know you use\n",
       "55:56 vision and you use navigation and that's\n",
       "55:59 how like that that based on that one\n",
       "56:01 project I got into Tesla. So uh I think\n",
       "56:05 it's a combination of knowing your\n",
       "56:07 fundamentals and doing relevant\n",
       "56:08 projects. So if you are if you do some\n",
       "56:12 computer vision related projects it's a\n",
       "56:14 very good start. It's very good to have\n",
       "56:16 on your resume so that the company knows\n",
       "56:19 that okay you're familiar with the space\n",
       "56:21 so they pick your resume and you can you\n",
       "56:23 at least get the chance to interview and\n",
       "56:24 then you like iterate and get better.\n",
       "56:27 Mhm. So, a good pet project could be uh\n",
       "56:31 you write an app that you just show like\n",
       "56:35 with use your that uses your camera to\n",
       "56:37 describe things that you have like you\n",
       "56:40 just point at your room and it says okay\n",
       "56:42 there is a bed uh uh there is like a\n",
       "56:46 clock and things like that right\n",
       "56:48 I think I saw that big with yo\n",
       "56:52 yeah like even with the LLMs it's gotten\n",
       "56:55 so much easier that you even if you like\n",
       "56:57 prompt an LM with the appropriate\n",
       "56:58 prompt. You don't need to train\n",
       "57:00 anything. It will just tell you whatever\n",
       "57:02 it is in the room.\n",
       "57:03 What else you can ask Chad GPT to write\n",
       "57:05 you this app and then you learn how we\n",
       "57:07 did this, I guess.\n",
       "57:10 Yeah, that's like two stages. You don't\n",
       "57:12 even write the app yourself. Corp can do\n",
       "57:15 it.\n",
       "57:16 But yeah, I asked recently um a tool\n",
       "57:21 like Corser, it's a coding agent. I\n",
       "57:24 asked it to implement a multi- aent\n",
       "57:27 system for evaluating uh projects that\n",
       "57:31 are on GitHub according to a set of\n",
       "57:33 criteria and then half a half a hour\n",
       "57:37 later I had a system that kind of works.\n",
       "57:40 I needed to tweak a it a little bit uh\n",
       "57:42 also with prompts and then it was\n",
       "57:44 working and then I could start studying\n",
       "57:46 the how it was implemented and I was\n",
       "57:48 okay that's nice now I also know how to\n",
       "57:51 do it. Yeah, it's it's fascinating to me\n",
       "57:55 like you know these kind of projects\n",
       "57:56 used to be projects and pet projects in\n",
       "57:58 college and you used to spend like weeks\n",
       "58:00 on it and now it's just done but still\n",
       "58:03 yeah I I tried using it once it gets\n",
       "58:05 stuck in some weird bugs that you\n",
       "58:07 yeah then you have to intervene and\n",
       "58:09 and like you have to also learn\n",
       "58:11 everything that the AI system came up\n",
       "58:14 with before you can fix the bug you have\n",
       "58:17 to know the entire code base\n",
       "58:19 and sometimes\n",
       "58:20 I think it's very good\n",
       "58:22 sorry go ahead\n",
       "58:23 Yeah, I think it's very good for setting\n",
       "58:24 a framework like when you're starting a\n",
       "58:26 whole new project from scratch and you\n",
       "58:28 want like a framework, it's really good\n",
       "58:29 with that. But if you want to get into\n",
       "58:31 the nitty-g gritties, you have to know\n",
       "58:33 what you're doing. Yeah.\n",
       "58:35 Okay.\n",
       "58:36 Okay. Um it was amazing talking to you.\n",
       "58:40 Um\n",
       "58:41 so thanks a lot. Uh good that we managed\n",
       "58:43 to work out work it out and find time\n",
       "58:46 that worked for us. Um, I'm sorry about\n",
       "58:50 uh you getting sick, so I hope you\n",
       "58:51 recover super quickly. So now I know\n",
       "58:54 it's very late for you, so you should go\n",
       "58:55 and rest and I'll go have breakfast.\n",
       "58:59 All right, have a good day. Nice to meet\n",
       "59:01 you.\n",
       "59:01 So thank you and thanks everyone for\n",
       "59:03 joining us today. Um, and</pre>\n",
       "            </div>\n",
       "\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The YouTube video features an interview with Aishwara, a machine learning engineer currently working at Vimo, who has previously worked on Tesla's autopilot AI team and has experience in various AI applications across different industries.</p>\n",
       "<h3>Key Highlights:</h3>\n",
       "<ol>\n",
       "<li><p><strong>Introduction and Background:</strong></p>\n",
       "<ul>\n",
       "<li>Aishwara discusses her career journey, which includes roles at Morgan Stanley dealing with big data and machine learning, and her work in computer vision, particularly involving autonomous systems.</li>\n",
       "<li>She shares her experiences in academia, including her time at Carnegie Mellon University.</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>AI for Social Good Projects:</strong></p>\n",
       "<ul>\n",
       "<li>Aishwara contributed to a project focused on malaria mapping in Africa, using satellite imagery and topographic data to identify areas needing fumigation to combat malaria.</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Current Role and Work:</strong></p>\n",
       "<ul>\n",
       "<li>Her current position involves working on gesture recognition within self-driving cars and understanding pedestrian behavior to improve autonomous vehicle navigation.</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Self-Driving Technology:</strong></p>\n",
       "<ul>\n",
       "<li>The discussion dives into the complexities of self-driving technology, highlighting how it integrates various models and data types (like computer vision and rule-based systems) to ensure safety and adherence to traffic regulations.</li>\n",
       "<li>Aishwara talks about the iterative process of deploying AI systems, emphasizing testing and validating models before real-world deployment.</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Learning and Career Advice:</strong></p>\n",
       "<ul>\n",
       "<li>She emphasizes the importance of having a strong foundation in deep learning and relevant projects when aspiring to work in the self-driving industry.</li>\n",
       "<li>Aishwara encourages those interested to engage in community projects and develop practical skills through coding and AI applications.</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Reinforcement Learning and AI Development:</strong></p>\n",
       "<ul>\n",
       "<li>The video touches on the usage of reinforcement learning in AI, the overlaps in techniques between computer vision and natural language processing, and the opportunities presented by large language models in future AI developments.</li>\n",
       "</ul>\n",
       "</li>\n",
       "<li><p><strong>Audience Interaction:</strong></p>\n",
       "<ul>\n",
       "<li>Viewers ask questions regarding self-driving technology, testing processes, and the integration of AI in various contexts, which Aishwara answers based on her expertise and experiences.</li>\n",
       "</ul>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Overall, the video serves as an informative dialogue on the intersections of AI, practical applications in self-driving technology, and the experiences of a professional in the field, while also addressing community-driven and social good projects.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "runner = OpenAIAgentsSDKRunner(\n",
    "    chat_interface=chat_interface,\n",
    "    agent=youtube_assistant\n",
    ")\n",
    "\n",
    "await runner.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0495c42-531c-4bc9-acf1-93af75aaac7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
